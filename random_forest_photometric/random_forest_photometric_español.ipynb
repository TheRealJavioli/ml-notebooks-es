{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Los Bosques Aleatorios y photo-zs (corrimientos al rojo)\n",
    "\n",
    "En este cuaderno, usaremos Bosques Aleatorios para estimar los 'redshifts' (corrimientos al rojo) fotométricos de galaxias, empezando con observaciones de magnitudes de galaxias en seis diferentes bandas fotométricas. Este cuaderno acompaña Capítulo 6 del libro.\n",
    "\n",
    "Queremos reproducir o mejorar los resultados de [este artículo](https://arxiv.org/abs/1903.08174) ; sus datos son públicamente disponibles [aquí](http://d-scholarship.pitt.edu/36064/).\n",
    "\n",
    "Autor: Viviana Acquaviva, con contibuciones de Jake Postiglione y Olga Privman. Traducido por Lucia Perez y Rosario Cecilio-Flores-Elie. "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "\n",
    "\n",
    "font = {'size'   : 16}\n",
    "matplotlib.rc('font', **font)\n",
    "matplotlib.rc('xtick', labelsize=14) \n",
    "matplotlib.rc('ytick', labelsize=14) \n",
    "matplotlib.rcParams.update({'figure.autolayout': False})\n",
    "matplotlib.rcParams['figure.dpi'] = 300"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_validate, KFold, cross_val_predict, GridSearchCV\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import astropy\n",
    "\n",
    "from astropy.io import fits\n",
    "\n",
    "#fits significa \"Flexible Image Transport System\" o \"Sistema Flexible para Transportar Imágenes\"; es un formata que puede guardar imágenes y datos sumarios\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ingreso de Datos"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En mi opinión, lo mas facil es leer los datos con un marco de datos de pandas:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "with fits.open('../data/DEEP2_uniq_Terapix_Subaru_v1.fits') as data:\n",
    "    df = pd.DataFrame(np.array(data[1].data).byteswap().newbyteorder()) #mirar https://numpy.org/devdocs/user/basics.byteswapping.html#changing-byte-ordering"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "df.columns"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "df.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "df.shape"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puedo escoger las columnas que corresponded al brillo de las galaxias en las seis bandas de interés."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "features = df[['u_apercor', 'g_apercor', 'r_apercor', 'i_apercor', 'z_apercor','y_apercor']]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El objetivo es identificar la caracteristica del corrimiento al rojo. Para este catologo, los corrimientos al rojo espectroscópicos (que son más precisos) están disponibles en esta columna:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "target = df['zhelio']"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "features.head(10)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "target.head(10)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¡Ahora podemos empezar nuestro primer modelo de Bosque Aleatorio!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para entender lo que queremos, miremos esta figura del artículo:\n",
    "\n",
    " ![Desempeño de la reconstruction de los corrimientos al rojo fotométricos](Photoz_RF_CFHTLS_Deep.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta figura, $\\sigma_{NMAD}$ es la mediana normalizada de la desviación absoluta del vector residual; y $\\eta$ es la fracción de valores atípicos, definidos como esos por cual (z_verdad - z_estimado)/(1+z_verdad) > 0.15.\n",
    "\n",
    "Para ser justos, estamos usando datos de DEEP2/3, entonces nuestro rango es un poco diferente."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "model = RandomForestRegressor()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "model.get_params()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Establecer el punto de referencia."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "scores = cross_validate(model,features,target, cv = KFold(n_splits=5, shuffle=True, random_state=10), return_train_score=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "scores"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¡Mosca que toma tiempo! Y las notas son las de R2 en este momento."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "np.mean(scores['test_score'])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "np.mean(scores['train_score'])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Revisión de aprendizaje\n",
    "    \n",
    "What issue do these scores indicate?\n",
    "\n",
    "¿Qué problema está indicado en estas notas?\n",
    "\n",
    "<br>\n",
    "\n",
    "<details>\n",
    "<summary style=\"display: list-item;\">¡Haga clic aquí para obtener la respuesta!</summary>\n",
    "<p>\n",
    "    \n",
    "```\n",
    "Parece que tenemos un gran problema de alta divergencia.\n",
    "```\n",
    "    \n",
    "</p>\n",
    "</details>\n",
    "\n",
    "¿Por qué?\n",
    "\n",
    "<br>\n",
    "\n",
    "<details>\n",
    "<summary style=\"display: list-item;\">¡Haga clic aquí para obtener la respuesta!</summary>\n",
    "<p>\n",
    "\n",
    "```\n",
    "\n",
    "Se ve una gran diferencia entre las notas de entrenamiento y de prueba. Para ser justos, debemos también mirar a la desviación estándar de las notas de entrenamiento y de prueba para confirmar que la diferencia es significativa.\n",
    "\n",
    "```\n",
    "    \n",
    "</p>\n",
    "</details>\n",
    "</br>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos también a ver a las predicciones:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "ypred = cross_val_predict(model,features,target, cv = KFold(n_splits=5, shuffle=True, random_state=10))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "plt.scatter(target,ypred, s = 20, c = 'royalblue')\n",
    "plt.xlabel('True (spectroscopic) z', fontsize=14)\n",
    "plt.ylabel('Predicted z',fontsize=14)\n",
    "plt.axis('square')\n",
    "plt.xlim(0,3)\n",
    "plt.ylim(0,3)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pregunta: ¿Se parecen a las del artículo?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También es interesante ver la distribución de los valores previstos, y ver que casi siempre producen una distribución más angosta. ¿Por qué?"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "plt.hist(target,bins=50,density=False,alpha=0.5, range = (0,3), label = 'True');\n",
    "plt.hist(ypred,bins=50,density=False,alpha=0.5, range = (0,3), color = 'g', label = 'Predicted');\n",
    "plt.legend(fontsize=14);"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora podemos calcular la fracción de valores atípicos:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "len(np.where(np.abs(target-ypred)>0.15*(1+target))[0])/len(target)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y el NMAD (\"normalized median absolute deviation\"):"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "1.48*np.median(np.abs(target-ypred)/(1 + target)) \n",
    "# Para una distribución Gaussiana, esto se hace una desviación estándar--por eso el 1.48"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tenemos un gran problema de muy alta divergencia, entonces podemos optimizar nuestros parámetros. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero podemos reducir el tamaño del conjunto de datos, especialmente porque ya vimos lo lento que fue usar los k-fold CV simples."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "np.random.seed(20)\n",
    "sel = np.random.choice(range(len(ypred)), 5000, replace = False) #tomar muestras sin reemplazarlas"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "len(np.unique(sel))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos un conjunto de datos más pequeño:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "seld = features.loc[sel,:]\n",
    "selt = target[sel]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "littlescores = cross_validate(model,seld,selt, cv = KFold(n_splits=5, shuffle=True, random_state=10), return_train_score=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "littlescores['test_score'].mean(), littlescores['train_score'].mean()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Que el desempeño es similar con el conjunto de entrenamiento nos asegura que el tamaño del conjunto no es un gran problema, y podemos seguir optimizando."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### parámetros del árbol\n",
    "\n",
    "Los parámetros asociados con esto son:\n",
    "\n",
    "- El número mínimo de casos en nódulo de hoja;\n",
    "\n",
    "- El número mínimo de casos requeridos en un nódulo partido; \n",
    "\n",
    "- La profundidad máxima del árbol;\n",
    "\n",
    "- El criterio que decide si un partido \"vale la pena\", que se expresa en términos del gano de información.\n",
    "\n",
    "\n",
    "#### parámetros del Aleatorización\n",
    "\n",
    "- El número de carácteristicas k < n que se usan en construir árboles;\n",
    "\n",
    "- El valor de retomar muestras (\"bootstrap\") del conjunto de datos (T or F, Verdad o Falso).\n",
    "\n",
    "#### parámetros del Bosque\n",
    "\n",
    "El número de árboles en el bosque (n_estimadores) se puede ajustar; se entiende que más árboles es mejor, pero eventualmente el desempeño se estabilizará, entonces podemos balancear el número de árboles y la duración del cada ronda (de entrenamiento, optimización, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "model.get_params()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imaginemos un conjunto posible."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- min_impurity_decrease (reducción mínima de la impureza)\n",
    "\n",
    "- número de Árboles\n",
    " \n",
    "- max_leaf_nodes (número maxímo de nódulos de hoja)\n",
    "\n",
    "- min_samples_split (número mínimo de conjuntos después de partirlos)\n",
    "\n",
    "- max_features (número maximo de carácteristicas)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Dura unos minutos terminar\n",
    "\n",
    "parameters = {'min_impurity_decrease':[0.1, 0.5, 0.0], \\\n",
    "              'max_features':[None,4,2], 'n_estimators':[50, 100, 200], 'min_samples_split': [10,20,100], \n",
    "              'max_leaf_nodes':[None, 100, 200]}\n",
    "nmodels = np.product([len(el) for el in parameters.values()])\n",
    "model = GridSearchCV(RandomForestRegressor(), parameters, cv = KFold(n_splits=5, shuffle=True), \\\n",
    "                     verbose = 2, n_jobs = 4, return_train_score=True)\n",
    "model.fit(seld,selt)\n",
    "\n",
    "print('Best params, best score:', \"{:.4f}\".format(model.best_score_), \\\n",
    "      model.best_params_)\n",
    "\n",
    "print('Los mejores parámetros, la mejor nota:', \"{:.4f}\".format(model.best_score_), \\\n",
    "      model.best_params_)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "scores = pd.DataFrame(model.cv_results_)\n",
    "scoresCV = scores[['params','mean_test_score','std_test_score','mean_train_score']].sort_values(by = 'mean_test_score', \\\n",
    "                                                    ascending = False)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "scoresCV"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Y el resultado es..."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NO mejoramos las notas de prueba."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¡Es el momento de considerar cómo limpiar o entrar los datos!\n",
    "\n",
    "En mi caso, tuve que escribirles a los autores del artículo original. Me dijeron exactamente cómo escogieron los datos para el conjunto de entrenamiento. "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "mags = df[['u_apercor', 'g_apercor', 'r_apercor', 'i_apercor', 'z_apercor','y_apercor','subaru_source','cfhtls_source','zquality']]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "mags.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "mags.shape"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# calidad del corrimiento al rojo - queremos solo usar objetos que tienen corrimientos al rojo (espectroscópicos) de alta calidad\n",
    "\n",
    "mags = mags[mags['zquality'] >= 3]\n",
    "\n",
    "mags.shape"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "#foto de cfhtls (profunda)\n",
    "\n",
    "mags = mags[mags['cfhtls_source'] == 0]\n",
    "\n",
    "mags.shape"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# No lo usaremos por ahora, pero esta es la foto profunda de subaru\n",
    "\n",
    "#mags = mags[mags['subaru_source'] == 0]\n",
    "\n",
    "#mags.shape"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Medidas no disponibles se señalan con -99 o 99 (valores típicos son 20-25). Podemos botar datos sin medidas."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "mags = mags[mags > -10].dropna()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "mags.shape"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "mags = mags[mags < 90].dropna()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "mags.shape"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nuestro conjunto final tiene 6,307 objetos y usa las 6 carácteristicas originales."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "sel_features = mags[['u_apercor', 'g_apercor', 'r_apercor', 'i_apercor', 'z_apercor','y_apercor']]\n",
    "sel_features.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Escogemos la misma colección en el vector de meta."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "sel_target = target[sel_features.index]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a ver cómo le va a nuestro modelo de referencia. Para tener resultados duplicables, tenemos que fijar el parámetro \"random\\_state\" (estado aleatorio, que controla el procesador de bootstrap) del Bosque Aleatorio, y la semilla aleatoria de la validación cruzada. "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "scores = cross_validate(RandomForestRegressor(random_state = 5),sel_features,sel_target,cv = KFold(n_splits=5, shuffle=True, random_state=10), \\\n",
    "               return_train_score=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(np.round(np.mean(scores['test_score']),3), np.round(np.std(scores['test_score']),3))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(np.round(np.mean(scores['train_score']),3), np.round(np.std(scores['train_score']),3))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¡Las notas si se mejoran! Pero, todavía se ve alta divergencia. Podemos rehacer el proceso de optimización (mosca que el tamaño del conjunto de datos ya está limitado, entonces no se tiene que encoger)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "#Esto me tomó ~3 minutos\n",
    "\n",
    "parameters = {'max_depth':[3, 6, None], \\\n",
    "              'max_features':[None,4,2], 'n_estimators':[50,100,200], 'min_samples_leaf': [1,5,10]}\n",
    "nmodels = np.product([len(el) for el in parameters.values()])\n",
    "model = GridSearchCV(RandomForestRegressor(random_state = 5), parameters, cv = KFold(n_splits=5, shuffle=True, random_state=10), \\\n",
    "                     verbose = 2, n_jobs = 4, return_train_score=True)\n",
    "model.fit(sel_features,sel_target)\n",
    "\n",
    "print('Best params, best score:', \"{:.4f}\".format(model.best_score_), \\\n",
    "      model.best_params_)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "scores = pd.DataFrame(model.cv_results_)\n",
    "scoresCV = scores[['params','mean_test_score','std_test_score','mean_train_score']].sort_values(by = 'mean_test_score', \\\n",
    "                                                    ascending = False)\n",
    "scoresCV"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Revisión de aprendizaje\n",
    "\n",
    "Viendo los resultados de la búsqueda en cuadrícula, ¿esperarías que el desempeño se mejoraría mucho si se agranda el espacio de los parámetros?\n",
    "\n",
    "<br>\n",
    "<details><summary><b>¡Haga clic aquí para obtener la respuesta!</b></summary>\n",
    "<p>\n",
    "    \n",
    "```\n",
    "Probablemente no, porque las notas no cambian mucho en los primero 10-20 modelos; eso sugiere que seguir optimizando no las mejoraría mucho.\n",
    "```\n",
    "    \n",
    "</p>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "bm = model.best_estimator_"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede generar una tanda de predicciones para visualizar lo que pasaría."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "ypred = cross_val_predict(bm, sel_features,sel_target, cv = KFold(n_splits=5, shuffle=True, random_state=10))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(7,7))\n",
    "plt.scatter(sel_target,ypred, s =10)\n",
    "plt.xlabel('z_spec')\n",
    "plt.ylabel('z_photo')\n",
    "plt.ylim(0,2)\n",
    "plt.xlim(0,2)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculemos la fracción de valores atípicos y comparemos con la figura."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "len(np.where(np.abs(sel_target-ypred)>0.15*(1+sel_target))[0])/len(sel_target)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculemos desviación absoluta mediana normalizada (Normalized Median Absolute Deviation, NMAD)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "1.48*np.median(np.abs(sel_target-ypred)/(1 + sel_target))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusión: ¿cómo se compara nuestro modelo con el del artículo?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El nuestro es un poco peor, pero tenemos una ventaja secreta en la ingeniería de características."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio en la ingeniería de Características: ¿qué pasaría si usamos los colores en lugar de las magnitudes?"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "sel_features.loc[:,'u-g'] = sel_features['u_apercor'] - sel_features['g_apercor']\n",
    "sel_features.loc[:,'g-r'] = sel_features['g_apercor'] - sel_features['r_apercor']\n",
    "sel_features.loc[:,'r-i'] = sel_features['r_apercor'] - sel_features['i_apercor']\n",
    "sel_features.loc[:,'i-z'] = sel_features['i_apercor'] - sel_features['z_apercor']\n",
    "sel_features.loc[:,'z-y'] = sel_features['z_apercor'] - sel_features['y_apercor']"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "sel_colors = sel_features[['u-g','g-r','r-i','i-z','z-y','i_apercor']]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "scores = cross_validate(RandomForestRegressor(),sel_colors,sel_target,cv = KFold(n_splits=5, shuffle=True, random_state=10), \\\n",
    "               return_train_score=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "scores "
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "scores['test_score'].mean(), scores['test_score'].std()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "parameters = {'max_depth':[3, 6, None], \\\n",
    "              'max_features':[None,4,2], 'n_estimators':[50,100,200], 'min_samples_leaf': [1,5,10]}\n",
    "nmodels = np.product([len(el) for el in parameters.values()])\n",
    "model = GridSearchCV(RandomForestRegressor(), parameters, cv = KFold(n_splits=5, shuffle=True), \\\n",
    "                     verbose = 2, n_jobs = 4, return_train_score=True)\n",
    "model.fit(sel_colors, sel_target)\n",
    "\n",
    "print('Best params, best score:', \"{:.4f}\".format(model.best_score_), \\\n",
    "      model.best_params_)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "scores = pd.DataFrame(model.cv_results_)\n",
    "scoresCV = scores[['params','mean_test_score','std_test_score','mean_train_score','mean_fit_time']].sort_values(by = 'mean_test_score', \\\n",
    "                                                    ascending = False)\n",
    "scoresCV"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "bm"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "bm = model.best_estimator_"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "ypred = cross_val_predict(bm, sel_colors, sel_target, cv = KFold(n_splits=5, shuffle=True, random_state=10))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Revisión de aprendizaje\n",
    "    \n",
    "Calcula el NMAD y la fracción de valores atípicos en los corrimientos al rojo predichos comparados con los verdaderos, completando este programa.\n",
    "\n",
    "```python\n",
    "1.48 * np.median(... (... - ...)/(1 + ...))\n",
    "\n",
    "len(... (np.abs(...) > ... * (1 + ...))[0]) / len(...)\n",
    "```\n",
    "\n",
    "<br>\n",
    "\n",
    "<details>\n",
    "<summary style=\"display: list-item;\">¡Haga clic aquí para obtener la respuesta!</summary>\n",
    "<p>\n",
    "    \n",
    "```python\n",
    "1.48 * np.median(np.abs(sel_target-ypred)/(1 + sel_target))\n",
    "\n",
    "len(np.where(np.abs(sel_target-ypred)>0.15*(1+sel_target))[0])/len(sel_target)\n",
    "```\n",
    "    \n",
    "</p>\n",
    "</details>\n",
    "</br>"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(7,7))\n",
    "plt.scatter(sel_target,ypred, s =10)\n",
    "plt.ylim(0,2)\n",
    "plt.xlim(0,2)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¡Por fin logramos el desempeño del artículo! (Pero mosca que no estamos usando *exactamente* los mismos datos.)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='blue'> Antes de hoy, no hemos hablado de algo muy importante: cómo estimar la incertidumbre asociada con nuestros resultados.</font>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una fuente de la dispersión viene de las métricas de desempeño global es la arquitectura de nuestra sistema: deberíamos generar muchas predicciones con muchas diferentes semillas aleatorias. Esto es el equivalente a la dispersión que se ve en las métricas monitorizadas (p.ej. notas de MSE o r2) en la validación cruzada."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "model = RandomForestRegressor(max_features=4, n_estimators=200) # tengo que \"re-sembrar\" el estado aleatorio"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Mosca, esto también es lentoooooo\n",
    "\n",
    "seeds = np.random.choice(100,8, replace = False) #pick 8\n",
    "\n",
    "olf = np.zeros(8)\n",
    "NMAD = np.zeros(8)\n",
    "\n",
    "for i in range(8): # Un poco básico, pero nos medio-muestra que pasa cuando se cambian las semillas aleatorias\n",
    "    print('Iteration', i)\n",
    "    ypred = cross_val_predict(RandomForestRegressor(max_features=4, n_estimators=200,random_state=seeds[i]), sel_features, sel_target, cv = KFold(n_splits=5, shuffle=True, random_state=seeds[i]))\n",
    "    olf[i] = len(np.where(np.abs(sel_target-ypred)>0.15*(1+sel_target))[0])/len(sel_target)\n",
    "    NMAD[i] = 1.48*np.median(np.abs(sel_target-ypred)/(1 + sel_target))\n",
    "\n",
    "print('OLF avg/std:, {0:.5f}, {1:0.5f}'.format(olf.mean(), olf.std()))\n",
    "print('NMAD avg/std:, {0:.5f}, {1:0.5f}'.format(NMAD.mean(), NMAD.std()))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sin embargo, tenemos que pensar cómo cuantificar el error observacional en cada una de nuestras entradas *individualmente*. \n",
    "\n",
    "No existe mucha literatura que explora esto, pero propongo un \"forward-pass\" (pase adelantado): ejecutamos el mejor modelo muchas veces, cada vez con entradas diferentes que obtenemos al modelar sus perfiles de ruido (p.ej. un Gaussian por cual el mediano es el valor medido, y sigma es el error experimental).\n",
    "\n",
    "Si supongamos quel perfil de ruido no cambia del valor \"verdadero\" al valor \"observado\", el debe incluir el error experimental y el error de \"información limitada\", que viene de tener un conjunto de entrenamiento limitado, carácteristicas no informativas, la arquitectura del modelo, etc. Esto se describe como incertidumbre \"epistemológica\" o \"aleatorica\" (p.ej. [esta reseña reciente](https://link.springer.com/article/10.1007/s10994-021-05946-3))."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
