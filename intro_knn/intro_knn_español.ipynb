{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Este es un cuaderno simple para construir y visualizar los algoritmos de kNN. \n",
    "Acompaña al Capítulo 2 de la clase.\n",
    "\n",
    "Autores: Viviana Acquaviva, con Jake Postiglione y Olga Privman. Traducción a Español por Lucia Perez y Rosario Cecilio-Flores-Elie."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "source": [
    "### Primero se introduce los módulos de python pertinentes\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "import pandas as pd \n",
    "\n",
    "import sklearn\n",
    "\n",
    "from sklearn.model_selection import train_test_split # Esta función no la usamos en este cuaderno, ¡pero es muy útil!\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier # cómo introducir los métodos de aprendizaje automático\n",
    "\n",
    "from sklearn import metrics # con esto podemos usar métricas de evaluación\n",
    "\n",
    "from sklearn import neighbors # y aquí entra el método de hoy, kNN"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# preparando cosas básicas para nuestra gráfica final\n",
    "font = {'size'   : 20}\n",
    "matplotlib.rc('font', **font)\n",
    "matplotlib.rc('xtick', labelsize=20) \n",
    "matplotlib.rc('ytick', labelsize=20) \n",
    "matplotlib.rcParams['figure.dpi'] = 300"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leer los datos del archivo"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "LearningSet = pd.read_csv('../data/HPLearningSet.csv')\n",
    "\n",
    "LearningSet = LearningSet.drop(LearningSet.columns[0], axis=1) # No necesitamos la primera columna de data, entonces la desechamos (\"drop\" aquí significa \"dejar caer\" de lo otro)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Ya sabemos como funcionan los marcos de datos de pandas\n",
    "\n",
    "LearningSet # Esto nos muestra las primeras 5 filas"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vamos a escoger los mismos conjuntos de aprendizaje y prueba que usamos en el ejercisio "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "TrainSet =  LearningSet.iloc[:13,:] #.iloc se usa para separar la estructura de la data usando los índices de la position\n",
    "\n",
    "TestSet = LearningSet.iloc[13:,:]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Se separan los conjuntos e aprendizaje y prueba entre características/atributos y etiquetas/clasificaciones"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "Xtrain = TrainSet.drop(['P_NAME','P_HABITABLE'],axis=1) # Esto nos da la masa estelar, el periodo, y la distancia\n",
    "\n",
    "Xtest = TestSet.drop(['P_NAME','P_HABITABLE'],axis=1)  # También nos da la masa estelar, el periodo, y la distancia"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "ytrain = TrainSet.P_HABITABLE # Esto indica la verdadera clasificación del conjunto de entrenamiento, o el output\n",
    "\n",
    "ytest = TestSet.P_HABITABLE # Esto indica la verdadera clasificación del conjunto de prueba, o el output"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estamos listos para implementar el algoritmo de kNN (\"k Nearest Neighbor\", o 'los k vecinos más cercanos') "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es un algoritmo simple, basado en la idea de distancia: buscamos los \"k\" objetos más cercanos (k aquí es un entero) al objeto que queremos clasificar, y decidir con la mayoría  entre las clases 'k' de los 'k' vecinos.  \n",
    "\n",
    "En este proceso, yo me pregunte: ¿pero a qué le falta para hacer \".fit()\"?  [Esta pagina](https://stats.stackexchange.com/questions/349842/why-do-we-need-to-fit-a-k-nearest-neighbors-classifier) (en Ingles) me lo explico bien. "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "model = neighbors.KNeighborsClassifier(n_neighbors = 3) # 'neighbors' = vecinos"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "model"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Revisión de aprendizaje:\n",
    "\n",
    "Pregunta: ¿Cómo se debe escribir código para aumentar los vecinos a 5? Pruébalo en la próxima celda."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# Escribe tu código aquí\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary style=\"display: list-item;\">¡Oprime aquí para la respuesta!</summary>\n",
    "<p>\n",
    "\n",
    "```python\n",
    "model = neighbors.KNeighborsClassifier(n_neighbors = 5)\n",
    "```\n",
    "\n",
    "</p>\n",
    "</details>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualicemos el modelo, pero solamente usando las primeras dos características/atributos para la sencillez. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Construimos el modelo para hacerle \"fit\" (o, encajar) al conjunto de aprendizaje; y predecir las etiquetas del conjunto de prueba."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Se pueden combinar los processors de encajar/predecir así, o usando el método de \"fit_predict\"\n",
    "\n",
    "model.fit(Xtrain.iloc[:,:2],ytrain) # así se entrena el modelo, que ahora se puede usar para predecir etiquetas\n",
    "\n",
    "ytestpred = model.predict(Xtest.iloc[:,:2]) # así se usa el modelo entrenado/encajado para predecir las etiquetas para los 5 objetos en el conjunto de prueba\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "ytestpred"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Revisión de aprendizaje: \n",
    "   \n",
    "Pregunta: ¿Se puede predecir las etiquetas para el conjunto de aprendizaje? ¿Cuál sería el código correcto? Prueba tu código en la próxima celda.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# Escribe tu código aquí\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary style=\"display: list-item;\">¡Oprime aquí para la respuesta!</summary>\n",
    "<p>\n",
    "\n",
    "```python\n",
    "ytrainpred = model.predict(Xtrain.iloc[:,:2])\n",
    "```\n",
    "\n",
    "</p>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "ytestpred, ytest.values #comparar"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pregunta: Calcula la exactitud el los resultados del conjunto de entrenamiento y el conjunto de prueba (las notas de entrenamiento y prueba)\n",
    "\n",
    "<details>\n",
    "<summary style=\"display: list-item;\">¡Oprime aquí para la respuesta!</summary>\n",
    "<p>\n",
    "\n",
    "   \n",
    "```markdown\n",
    "~ 0.692\n",
    "    \n",
    "0.8\n",
    "```\n",
    "   \n",
    "</p>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(metrics.accuracy_score(ytrain, model.predict(Xtrain.iloc[:,:2]))) # esto compara las etiquetas verdaderas para el conjunto de aprendizaje con las etiquetas previstas para el mismo conjunto\n",
    "\n",
    "print(metrics.accuracy_score(ytest, model.predict(Xtest.iloc[:,:2]))) # lo mismo que se acaba de hacer, pero para el conjunto de prueba\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pregunta: ¿Cuáles serían las exactitudes del entrenamiento y de la prueba si subimos el número de vecinos a 5?  \n",
    "\n",
    "<details>\n",
    "<summary style=\"display: list-item;\">¡Oprime aquí para la respuesta!</summary>\n",
    "<p>\n",
    "   \n",
    "```\n",
    "~ 0.615\n",
    "0.8\n",
    "```\n",
    "   \n",
    "</p>\n",
    "</details>\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Después de encajar y predecir, podemos ver los 'k' vecinos para cada elemento en el conjunto de prueba así:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "model.kneighbors(Xtest.iloc[:,:2]) # el primero elemento da las distancies, el segundo los índices"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ahora podemos visualizar los resultados, como hicimos con los árboles de decisión."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos imaginar las distancias más grandes como los radios de círculos--cada punto drentro del círculo es un vecino.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "for i in range(len(TestSet)): # vemos cada elemento del conjunto de prueba en orden  \n",
    "    \n",
    "    print(model.kneighbors(Xtest.iloc[:,:2])[0][i,2]) # esto imprime el tercer elemento del vector de distancias "
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "cmap = matplotlib.colors.LinearSegmentedColormap.from_list(\"\", ['#20B2AA','#FF00FF'])\n",
    "\n",
    "a = plt.scatter(TrainSet['S_MASS'], TrainSet['P_PERIOD'], marker=\"$\\u2606$\", facecolor = 'none',\\\n",
    "            c = TrainSet['P_HABITABLE'], s = 100, label = 'Train', cmap=cmap)\n",
    "\n",
    "a = plt.scatter(TestSet['S_MASS'], TestSet['P_PERIOD'], marker=\"$\\u25EF$\",facecolors = 'none',\\\n",
    "            c = TestSet['P_HABITABLE'], s = 100, label = 'Test', cmap=cmap)\n",
    "\n",
    "for i in range(len(TestSet)): # trazamos los vecinos \n",
    "\n",
    "    circle1=plt.Circle((TestSet['S_MASS'].iloc[i],TestSet['P_PERIOD'].iloc[i]),model.kneighbors(Xtest.iloc[:,:2])[0][i,2],\\\n",
    "                       lw = 0.7, edgecolor='k',facecolor='none')\n",
    "    plt.gca().add_artist(circle1)\n",
    "    \n",
    "plt.gca().set_aspect(1)\n",
    "\n",
    "bluepatch = mpatches.Patch(color='#20B2AA', label='Not Habitable') # los planetas no habitables marcados en azul/cian\n",
    "magentapatch = mpatches.Patch(color='#FF00FF', label='Habitable') # los planetas habitables maracados en rosado\n",
    "\n",
    "plt.legend();\n",
    "\n",
    "ax = plt.gca()\n",
    "leg = ax.get_legend()\n",
    "leg.legendHandles[0].set_color('k')\n",
    "leg.legendHandles[0].set_facecolor('none')\n",
    "leg.legendHandles[1].set_color('k')\n",
    "leg.legendHandles[1].set_facecolor('none')\n",
    "\n",
    "\n",
    "plt.legend(handles=[leg.legendHandles[0],leg.legendHandles[1], magentapatch, bluepatch],\\\n",
    "           loc = 'upper left', fontsize = 14)\n",
    "\n",
    "plt.xlim(-130,70)\n",
    "plt.ylim(0,140)\n",
    "plt.xlabel('Mass of Parent Star (Solar Mass Units)')\n",
    "plt.ylabel('Period of Orbit (days)');\n",
    "\n",
    "#plt.savefig('HabPlanetsKNN2features.png', dpi = 300)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¿Te has dado cuenta de un problema aquí?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Si una dimensión tiene un rango mucho mas grande que las toras, dominará el procesador de decisión. Podemos resolver este asunto usando <b> escalas </b>. Escalar valores es una etapa de pre-procesar los datos muy importante para muchos algoritmos de aprendizaje inteligente.\n",
    "\n",
    "[Aquí](https://scikit-learn.org/stable/auto_examples/preprocessing/plot_all_scaling.html) están ejemplos de diferentes algoritmos para escalar datos.\n",
    "\n",
    "Usaremos <i>RobustScaler</i> (literalmente: escalador robusto), que resiste mejor datos aislados que la versión regular.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "scaler = sklearn.preprocessing.RobustScaler()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "scaler.fit(Xtrain) #  IMPORTANTE: solo se escala el conjunto de prueba."
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "scaledXTrain = scaler.transform(Xtrain)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "scaledXTrain"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "scaledXtest = scaler.transform(Xtest) # mosca que ahora tenemos matrices de numpy, no \"data frames\"/marcos de datos de pandas"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "scaler.inverse_transform # así se deshace la escalación "
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "model.fit(scaledXTrain[:,:2],ytrain).predict(scaledXtest[:,:2])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "model.kneighbors(scaledXtest[:,:2]) # ahora las distancias a los vecinos para objetos en el conjunto de prueba se ven más balanceados"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(10,6))#, aspect_ratio = 'equal')\n",
    "cmap = matplotlib.colors.LinearSegmentedColormap.from_list(\"\", ['#20B2AA','#FF00FF'])\n",
    "plt.scatter(scaledXTrain[:,0], scaledXTrain[:,1], marker = '*',\\\n",
    "            c = ytrain, s = 100, label = 'Train', cmap=cmap) #, \n",
    "\n",
    "plt.scatter(scaledXtest[:,0], scaledXtest[:,1], marker = 'o',\\\n",
    "            c = ytest, s = 100, label = 'Test', cmap=cmap) #label = ,\n",
    "\n",
    "for i in range(len(TestSet)):\n",
    "\n",
    "    circle1=plt.Circle((scaledXtest[i,0],scaledXtest[i,1]),model.kneighbors(scaledXtest[:,:2])[0][i,2],\\\n",
    "                       edgecolor='k',facecolor='none', lw = 0.7)\n",
    "    plt.gca().add_artist(circle1)\n",
    "\n",
    "plt.gca().set_aspect(1)\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "ax = plt.gca()\n",
    "leg = ax.get_legend()\n",
    "leg.legendHandles[0].set_color('k')\n",
    "#leg.legendHandles[0].set_facecolor('none')\n",
    "leg.legendHandles[1].set_color('k')\n",
    "#leg.legendHandles[1].set_facecolor('none')\n",
    "\n",
    "\n",
    "plt.legend(handles=[leg.legendHandles[0], leg.legendHandles[1]], loc = 'upper right', fontsize = 14)\n",
    "\n",
    "plt.xlabel('Mass of Parent Star (Earth Mass Units)')\n",
    "plt.ylabel('Period of Orbit (days)');\n",
    "\n",
    "\n",
    "plt.xlim(-2.5,2.5)\n",
    "plt.ylim(-1.,2.5);\n",
    "\n",
    "#plt.savefig('HabPlanetsKNNscaled.png', dpi = 300)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mosca: cuando estemos aplicando los algoritmos kNN (no solamente visualizarlos), se deben usar todas las características."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comentarios finales:     \n",
    "    \n",
    "¡kNN necesita escalar datos! ¿Es que los árboles de decisión tienen el mismo problema?\n",
    "\n",
    "¿Qué piensas de la fortaleza o limitación de kNN?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
