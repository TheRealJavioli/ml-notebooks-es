{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"id":"TIb7AW-J_Q0j"},"source":["En este sencillo cuaderno, utilizamos una red neuronal totalmente conectada para resolver un problema de clasificación visto anteriormente: el problema de identificación de la física de partículas.\n","\n","Acompaña al Capítulo 8 del libro.\n","\n","Autora: Viviana Acquaviva, con contribuciones de Jake Postiglione y Olga Privman.\n","Traducido por Lucia Perez y Rosario Cecilio-Flores-Elie. \n","Licencia: [BSD-3-clause](https://opensource.org/license/bsd-3-clause/)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wCi2a2GB_Q0m"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","from scipy import stats\n","from sklearn.model_selection import train_test_split\n","from sklearn.model_selection import KFold\n","from sklearn.utils import shuffle"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ty1aqrju_Q0m"},"outputs":[],"source":["import matplotlib\n","import matplotlib.pyplot as plt\n","\n","pd.set_option('display.max_columns', 100)\n","pd.set_option('display.max_rows', 100)\n","pd.set_option('display.max_colwidth', 150)\n","\n","font = {'size'   : 16}\n","matplotlib.rc('font', **font)\n","matplotlib.rc('xtick', labelsize=14) \n","matplotlib.rc('ytick', labelsize=14) \n","matplotlib.rcParams['figure.dpi'] = 300"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"RELqQBID_Q0n"},"source":["Tensorflow es una biblioteca muy utilizada en el desarrollo de modelos de aprendizaje profundos. Es una plataforma de código abierto desarrollada por Google. Admite la programación en varios lenguajes, p. C++, Java, Python y muchos otros.\n","\n","Keras es una API (interfaz de programación de aplicaciones) de alto nivel que se basa en TensorFlow (o Theano, otra biblioteca de aprendizaje profundo). Es específico de Python y podemos considerarlo como el equivalente de la biblioteca sklearn para redes neuronales. Es menos general y menos personalizable, pero es muy fácil de usar y comparativamente más fácil que TensorFlow. Usaremos keras con el back-end de tensorflow."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fAX7Ddfd_Q0n"},"outputs":[],"source":["import tensorflow as tf"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qN9_Zvz0_fE_"},"outputs":[],"source":["tf.__version__"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lzdIblJi_Q0n"},"outputs":[],"source":["import keras\n","\n","from keras.models import Sequential #el modelo se construye agregando capas una tras otra\n","\n","from keras.layers import Dense #capas totalmente conectadas: cada salida habla con cada entrada\n","\n","from keras.layers import Dropout #para la regularización"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"AddTCBp6_Q0o"},"source":["Comenzamos con el problema 4top vs ttbar, y usamos la configuración donde agregamos las características \"número de leptones\", \"número de chorros\", etc. Como referencia, el SVM óptimo logró una precisión del 94-95%. Tenga en cuenta que esos números no se habían ejecutado a través de una validación cruzada <b> anidada </b>, por lo que podrían ser ligeramente optimistas."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GdeqbK8B_Q0o"},"outputs":[],"source":["X = pd.read_csv('../data/Features_lim_2.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"U-Qxlpua_Q0p"},"outputs":[],"source":["y = np.genfromtxt('../data/Labels_lim_2.txt')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QLOOvTME_Q0q"},"outputs":[],"source":["X.values.shape"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"eo9nE9rL_Q0r"},"source":["No hay un proceso de validación cruzada \"incorporado\" (o validación cruzada anidada), por lo que tendríamos que construirlo nosotros mismos. Por ahora, podemos construir tres conjuntos: entrenar, validar (para optimización de parámetros) y probar (para evaluación final). Idealmente, deberíamos construir esto como una estructura de validación cruzada."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jGV2FTWj_Q0y"},"outputs":[],"source":["#Siempre barajar primero\n","\n","X,y = shuffle(X,y, random_state = 10)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XolI39tH_Q0y"},"outputs":[],"source":["X_train = X.values[:3000,:]\n","y_train = y[:3000]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rLRFgtDm_Q0y"},"outputs":[],"source":["X_val = X.values[3000:4000,:]\n","y_val = y[3000:4000]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Nn046-as_Q0z"},"outputs":[],"source":["X_test = X.values[4000:,:]\n","y_test = y[4000:]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZZmgrG6Y_Q0z"},"outputs":[],"source":["X_train.shape, X_val.shape, X_test.shape"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"x6644VLi_Q0z"},"source":["### Construyendo la red"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"Ws9Ko4wv_Q0z"},"source":["Pensemos en la arquitectura del modelo.\n","\n","Nuestra capa de entrada tiene 24 neuronas.\n","\n","Nuestra capa de salida tiene una neurona (lo que sale es la probabilidad que el objeto pertenezca a la clase positiva). También podríamos configurarlo como dos neuronas (y tener softmax como la no linealidad final), pero esto es redundante en un problema de clasificación binaria.\n","\n","Agregaremos dos capas ocultas. Aquí estoy haciendo sus tamaños = 20 (¡debería optimizar este hiperparámetro!). También podemos reservar la posibilidad de añadir una capa de dropout después de cada uno. La fracción de abandono (\"dropout\") también debe optimizarse a través de VC.\n","\n","Otras decisiones que tenemos que tomar son: qué no linealidades usamos (por ahora: ReLU para capas ocultas, sigmoid para la final), qué optimizador usamos (Adam), qué tasa de aprendizaje inicial adoptamos (aquí 0.001, pero nuevamente esto debe decidirse a través de VC), el número de épocas (por ejemplo, 100; podemos trazar cantidades de interés para verificar que tenemos suficiente), el tamaño del lote para el paso de descenso del gradiente (aquí 200, ¡pero puede explorar!) y la función de pérdida . La última es la entropía cruzada binaria, que es la opción estándar para los problemas de clasificación en los que generamos una probabilidad. Premia la \"confianza\" en una predicción correcta (alta probabilidad)."]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"ssa1M_xP_Q00"},"source":["Los siguientes comandos se pueden utilizar para explorar estas opciones."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zUYax3cN_Q00"},"outputs":[],"source":["dir(keras.optimizers)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IlvBNdKG_Q00"},"outputs":[],"source":["dir(keras.losses)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"ppQRvorFEKRc"},"source":["Una opción estándar para un caso como el nuestro, donde las etiquetas son 0/1 pero podemos predecir una probabilidad, es la entropía cruzada binaria o pérdida logarítmica:\n","\n","L = - $\\frac{1}{N} \\sum_{i=1}^N y_i \\cdot log(p(y_i)) + (1-y_i) \\cdot log (1 - p(y_i))$"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"IpxfJMetEn6K"},"source":["p es la probabilidad de que un objeto pertenezca a la clase positiva. Penaliza los ejemplos positivos que están asociados con una baja probabilidad prevista y los ejemplos negativos que están asociados con una alta probabilidad prevista."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0wbZTVBd_Q00"},"outputs":[],"source":["dir(keras.activations)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"otwhTPnm_Q01"},"source":["### Así es como construimos una red neuronal completamente conectada en keras.\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"woqxQqX1_Q01"},"outputs":[],"source":["model = Sequential()\n","\n","# Agregue una capa de entrada y especifique su tamaño (número de características originales)\n","\n","model.add(Dense(20, activation='relu', input_shape=(24,)))\n","\n","# Agregue una capa oculta y especifique su tamaño\n","\n","model.add(Dense(20, activation='relu'))\n","\n","# Agregar una capa de salida\n","\n","model.add(Dense(1, activation='sigmoid'))\n","\n","optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n","\n","model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics = ['accuracy']) "]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"mfWlB-0NA6CM"},"source":["La palabra clave \"métrica\" aquí sirve para especificar otras posibles métricas que nos gustaría monitorear. La pérdida en sí no es interpretable, por lo que estaremos atentos a la precisión."]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"-lkvPwRy_Q01"},"source":["### ¿Listo para encajar?\n","\n","¡Eso espero! Tenga en cuenta también los hiperparámetros adicionales \"épocas\" (el número de pasajes de ida y vuelta) y el tamaño del lote (cuántos de los datos se utilizan en cada paso en la actualización de los pesos)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4a2GD11m_Q01"},"outputs":[],"source":["mynet = model.fit(X_train, y_train, validation_data= (X_val, y_val), epochs = 100,  batch_size=200)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"3gSnZtIbBXgQ"},"source":["Esto no se ve tan bien."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0rk8Pbdt_Q01"},"outputs":[],"source":["plt.hist(model.predict(X_test), alpha = 0.5, label = 'pred')\n","plt.hist(y_test, alpha = 0.5, label = 'true')\n","plt.legend();"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"nmdX7xQI_Q01"},"source":["También es útil trazar las pérdidas de entrenamiento y validación a lo largo de las épocas."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ekaBUX5j_Q01"},"outputs":[],"source":["plt.figure(figsize=(14,5))\n","\n","plt.subplot(121)\n","\n","plt.plot(mynet.history['loss'], label = 'train')\n","plt.plot(mynet.history['val_loss'],'-.m', label = 'validation')\n","plt.ylabel('Loss', fontsize = 14)\n","plt.xlabel('Epoch', fontsize = 14)\n","plt.legend(loc='upper right', fontsize = 12)\n","\n","plt.subplot(122)\n","\n","plt.plot(mynet.history['accuracy'], label = 'train')\n","plt.plot(mynet.history['val_accuracy'], '-.m', label = 'validation')\n","plt.ylabel('Accuracy', fontsize = 14)\n","plt.xlabel('Epoch', fontsize = 14)\n","plt.legend(fontsize = 12)\n","plt.subplots_adjust(wspace=0.5)\n","\n","#plt.show()\n","\n","#plt.savefig('FirstNN.png', dpi= 300)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"nJLdMkyp_Q01"},"source":["### Revisión de aprendizaje\n","    \n","Mirando a los gráficos anteriores, ¿cómo diría que le está yendo a este clasificador? ¿Sufre de alta varianza o alto sesgo?\n","\n","<br>\n","\n","<details>\n","<summary style=\"display: list-item;\">Haga clic aquí para la respuesta!</summary>\n","<p>\n","    \n","```\n","Los puntajes de entrenamiento y validación están cercanos, por lo que es un problema de alto sesgo, no de alta varianza. Esto se confirma por el hecho de que las notas son realmente bajas: alrededor del 70 % de precisión, en comparación con el > 90 % que obtuvimos con las SVM.\n","```\n","\n","</p>\n","</details>"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"0CQnFklgkduv"},"source":["### Cuando algo sale mal, nuestro primer paso siempre debe ser volver a los fundamentos de la exploración/configuración de datos."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PzmnBG7__Q01"},"outputs":[],"source":["X.describe()"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"FRv36Ye0tXMo"},"source":["### ¡Sí, nos olvidamos de escalar!"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2qQMC772_Q02"},"outputs":[],"source":["from sklearn.preprocessing import StandardScaler"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"T03xoxwA_Q02"},"outputs":[],"source":["scaler = StandardScaler()"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"gZskGuzakduw"},"source":["### Revisión de aprendizaje\n","    \n","Aplique el escalador anterior a la muestra correcta.\n","\n","<br>\n","\n","<details>\n","<summary style=\"display: list-item;\">Haga clic aquí para la respuesta!</summary>\n","<p>\n","\n","Como de costumbre, ¡solo usamos el conjunto de entrenamiento para derivar la escala! Necesitamos correr:\n","\n","```python\n","scaler.fit(X_train)\n","```\n","\n","</p>\n","</details>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qg4iHsoAkduw"},"outputs":[],"source":["#¡Ejecute el código de la revisión de aprendizaje para continuar!\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"vZV3gFOkkduw"},"source":["Ahora podemos usar el escalador ajustado para transformar los conjuntos de datos relevantes.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wLxWmWCk_Q03"},"outputs":[],"source":["Xst = scaler.transform(X)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"81RPh-OL_Q03"},"outputs":[],"source":["Xst.mean(axis=1) #Mosca: ¡no exactamente cero en todo el conjunto de datos!"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nczuqWMB_Q03"},"outputs":[],"source":["Xst_train = scaler.transform(X_train)\n","Xst_val = scaler.transform(X_val)\n","Xst_test = scaler.transform(X_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZIBbWjR9_Q03"},"outputs":[],"source":["mynet = model.fit(Xst_train, y_train, validation_data= (Xst_val, y_val), epochs=100, batch_size=200)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fjSveqjQ_Q03"},"outputs":[],"source":["plt.figure(figsize=(14,5))\n","\n","plt.subplot(121)\n","\n","plt.plot(mynet.history['loss'], label = 'train')\n","plt.plot(mynet.history['val_loss'],'-.m', label = 'validation')\n","plt.ylabel('Loss', fontsize = 14)\n","plt.xlabel('Epoch', fontsize = 14)\n","plt.legend(loc='upper right', fontsize = 12)\n","\n","plt.subplot(122)\n","\n","plt.plot(mynet.history['accuracy'], label = 'train')\n","plt.plot(mynet.history['val_accuracy'], '-.m', label = 'validation')\n","plt.ylabel('Accuracy', fontsize = 14)\n","plt.xlabel('Epoch', fontsize = 14)\n","plt.legend(fontsize = 12)\n","plt.subplots_adjust(wspace=0.5)\n","#plt.show()\n","\n","#plt.savefig('ScaledNN.png', dpi= 300)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"n6DzApbMkduy"},"source":["### Revisión de aprendizaje\n","    \n","¿Cuál es su evaluación del clasificador anterior? \n","<br>\n","\n","<details><summary><b>¡Haga clic aquí para obtener la respuesta!</b></summary>\n","<p>\n","    \n","```\n","El rendimiento ahora es comparable al que habíamos obtenido con SVM. Hay indicios de alta varianza/sobreajuste, como lo muestra la brecha entre las notas del entrenamiento y la validación; es difícil saber cuán significativa es la brecha sin un enfoque de validación cruzada. También podemos ver que la pérdida de validación está aumentandose; esto indica que alguna técnica de regularización, como la detención anticipada y/o una capa de abandono, podría ayudar aquí.\n","```"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zF4Dll3N_Q04"},"outputs":[],"source":["model = Sequential()\n","\n","# Agregue una capa de entrada y especifique su tamaño (número de características originales)\n","\n","model.add(Dense(20, activation='relu', input_shape=(24,)))\n","\n","model.add(Dropout(0.2)) #Esta es la fracción de abandono\n","\n","# Agregue una capa oculta y especifique su tamaño\n","\n","model.add(Dense(20, activation='relu'))\n","\n","model.add(Dropout(0.2)) #Esta es la fracción de abandono\n","\n","# Agregar una capa de salida\n","\n","model.add(Dense(1, activation='sigmoid'))\n","\n","optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n","\n","model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics = ['accuracy']) \n","\n","#La palabra clave métrica aquí es para otras posibles métricas que nos gustaría monitorear"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"g5WAqdzI_Q04"},"outputs":[],"source":["mynet = model.fit(Xst_train, y_train, validation_data= (Xst_val, y_val), epochs=100, batch_size=200)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"__hX7-bv_Q04"},"outputs":[],"source":["plt.figure(figsize=(14,5))\n","\n","plt.subplot(121)\n","\n","plt.plot(mynet.history['loss'], label = 'train')\n","plt.plot(mynet.history['val_loss'],'-.m', label = 'validation')\n","plt.ylabel('Loss', fontsize = 14)\n","plt.xlabel('Epoch', fontsize = 14)\n","plt.legend(loc='upper right', fontsize = 12)\n","\n","plt.subplot(122)\n","\n","plt.plot(mynet.history['accuracy'], label = 'train')\n","plt.plot(mynet.history['val_accuracy'], '-.m', label = 'validation')\n","plt.ylabel('Accuracy', fontsize = 14)\n","plt.xlabel('Epoch', fontsize = 14)\n","plt.legend(fontsize = 12)\n","plt.subplots_adjust(wspace=0.5)\n","\n","#plt.savefig('RegularizedNN.png', dpi= 300)\n","#plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pbWoRs0J_Q04"},"outputs":[],"source":["#Evaluación final del modelo (mosca: esto se hace en el conjunto de prueba por lo que si hacemos optimización de parámetros en el pliegue de validación, este quedará afuera).\n","\n","scores = model.evaluate(Xst_test, y_test, verbose=1)\n","\n","print(\"Accuracy: %.2f%%\" % (scores[1]*100)) #\"scores\" (notas) contiene la pérdida de prueba y la precisión, que estamos monitoreando"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PtWa7nxw_Q04"},"outputs":[],"source":["scores"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"}},"nbformat":4,"nbformat_minor":0}
