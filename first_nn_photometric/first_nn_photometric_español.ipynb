{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "TIb7AW-J_Q0j"
   },
   "source": [
    "En este sencillo cuaderno, usamos una red neuronal completamente conectada para resolver un problema visto anteriormente en regresión: el problema del corrimiento al rojo fotométrico.\n",
    "\n",
    "Acompaña al Capítulo 8 del libro.\n",
    "\n",
    "Autora: Viviana Acquaviva, con contribuciones de Jake Postiglione y Olga Privman.Traducido por Lucia Perez y Rosario Cecilio-Flores-Elie. \n",
    "\n",
    "License: [BSD-3-clause](https://opensource.org/license/bsd-3-clause/)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "wCi2a2GB_Q0m"
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.utils import shuffle"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Ty1aqrju_Q0m"
   },
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_colwidth', 150)\n",
    "\n",
    "font = {'size'   : 16}\n",
    "matplotlib.rc('font', **font)\n",
    "matplotlib.rc('xtick', labelsize=14) \n",
    "matplotlib.rc('ytick', labelsize=14) \n",
    "matplotlib.rcParams['figure.dpi'] = 300"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "RELqQBID_Q0n"
   },
   "source": [
    "Tensorflow es una biblioteca muy utilizada en el desarrollo de modelos de aprendizaje profundos. Es una plataforma de código abierto desarrollada por Google. Admite la programación en varios lenguajes, p. C++, Java, Python y muchos otros.\n",
    "\n",
    "Keras es una API (interfaz de programación de aplicaciones) de alto nivel que se basa en TensorFlow (o Theano, otra biblioteca de aprendizaje profundo). Es específico de Python y podemos considerarlo como el equivalente de la biblioteca sklearn para redes neuronales. Es menos general y menos personalizable, pero es muy fácil de usar y comparativamente más fácil que TensorFlow. Usaremos keras con el back-end de tensorflow."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "fAX7Ddfd_Q0n"
   },
   "source": [
    "import tensorflow as tf"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "qN9_Zvz0_fE_"
   },
   "source": [
    "tf.__version__"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "2qQMC772_Q02"
   },
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "lzdIblJi_Q0n"
   },
   "source": [
    "import keras\n",
    "\n",
    "from keras.models import Sequential #el modelo se construye añadiendo capas una tras otra\n",
    "\n",
    "from keras.layers import Dense #capas totalmente conectadas: cada salida habla con cada entrada\n",
    "\n",
    "from keras.layers import Dropout #para la regularización"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "gPe5Uv5D_xoZ"
   },
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/gdrive')\n",
    "# %cd /gdrive"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "sLHnWtsJ_Q04"
   },
   "source": [
    "### Problema 2: corrimientos al rojo fotométricos\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "T6-Ir38f_Q05"
   },
   "source": [
    "Comenzaré con el conjunto de datos reducido (de alta calidad) que usamos para los métodos de Boosting y Bagging. Como referencia, nuestro mejor modelo logró un NMAD de alrededor de 0,02 y una fracción atípica del 4 %."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "e8hFO3qM_Q05"
   },
   "source": [
    "X = pd.read_csv('../data/sel_features.csv', sep = '\\t')\n",
    "y = pd.read_csv('../data/sel_target.csv')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "100MCfNg_Q05"
   },
   "source": [
    "X,y = shuffle(X,y, random_state = 12)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "7JEkymDS_Q05"
   },
   "source": [
    "fifth = int(len(y)/5)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "II0EN1pV_Q05"
   },
   "source": [
    "X_train = X.values[:3*fifth,:]\n",
    "y_train = y[:3*fifth]\n",
    "\n",
    "X_val = X.values[3*fifth:4*fifth,:]\n",
    "y_val = y[3*fifth:4*fifth]\n",
    "\n",
    "X_test = X.values[4*fifth:,:]\n",
    "y_test = y[4*fifth:]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "4aHqfJPv_Q05"
   },
   "source": [
    "¡Sabemos que necesitamos escalar!"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "lGcMKwtu_Q05"
   },
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "scaler.fit(X_train)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "oaMj1-O0_Q06"
   },
   "source": [
    "Xst_train = scaler.transform(X_train)\n",
    "Xst_val = scaler.transform(X_val)\n",
    "Xst_test = scaler.transform(X_test)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "r1zYQ1yg_Q06"
   },
   "source": [
    "En un problema de regresión, elegiremos una activación diferente para la capa de salida (por ejemplo, lineal) y una función de pérdida diferente (MSE, MAE, ...).\n",
    "\n",
    "Nuestra capa de entrada tiene seis neuronas para este problema.\n",
    "\n",
    "Para otros parámetros y la estructura de la red, podemos comenzar con dos capas con 100 neuronas e ir desde allí."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "EaKOc1pv_Q06"
   },
   "source": [
    "dir(keras.activations)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "aej9n5gY_Q06"
   },
   "source": [
    "dir(keras.losses)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "t37u_TiV_Q06"
   },
   "source": [
    "model = Sequential()\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "# Agregue una capa de entrada y especifique su tamaño (número de características originales)\n",
    "\n",
    "model.add(Dense(100, activation='relu', input_shape=(6,)))\n",
    "\n",
    "#model.add(Dropout(0.2))\n",
    "\n",
    "# Agregue una capa oculta y especifique su tamaño\n",
    "\n",
    "model.add(Dense(100, activation='relu'))\n",
    "\n",
    "#model.add(Dropout(0.2))\n",
    "\n",
    "# Agregue una capa oculta y especifique su tamaño\n",
    "\n",
    "#model.add(Dense(30, activation='relu'))\n",
    "\n",
    "# Agregue una capa oculta y especifique su tamaño\n",
    "\n",
    "#model.add(Dense(12, activation='relu'))\n",
    "\n",
    "#model.add(Dropout(0.2))\n",
    "\n",
    "# Agregar una capa de salida\n",
    "\n",
    "model.add(Dense(1, activation='linear'))\n",
    "\n",
    "model.compile(loss='mse', optimizer=optimizer)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "C_pO8Jjl_Q06"
   },
   "source": [
    "Comenzamos con 100 épocas y tamaño de lote = 300."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "EpC58myL_Q06"
   },
   "source": [
    "mynet = model.fit(Xst_train, y_train, validation_data= (Xst_val, y_val), epochs=100, batch_size=300)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "R9F0vSIG_Q07"
   },
   "source": [
    "results = model.evaluate(Xst_test, y_test)\n",
    "print('MSE:', results) #solo estamos monitoreando MSE"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "6o1--T2H_Q07"
   },
   "source": [
    "As usual, we can plot the loss."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "igJTaSwy_Q07"
   },
   "source": [
    "plt.plot(mynet.history['loss'], label = 'train')\n",
    "plt.plot(mynet.history['val_loss'],'-.m', label = 'validation')\n",
    "plt.ylabel('Loss', fontsize = 14)\n",
    "plt.xlabel('Epoch', fontsize = 14)\n",
    "plt.legend(loc='upper right', fontsize = 12)\n",
    "plt.legend(fontsize = 12);\n",
    "#plt.savefig('Photoz_NN.png')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "4j5LEBae_Q07"
   },
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "    \n",
    "plt.xlabel('True redshift', fontsize = 14)\n",
    "plt.ylabel('Estimated redshift', fontsize = 14)\n",
    "\n",
    "plt.scatter(y_test, model.predict(Xst_test), s =10, c = 'teal');\n",
    "\n",
    "plt.xlim(0,2)\n",
    "plt.ylim(0,2)\n",
    "plt.tight_layout()\n",
    "#plt.savefig('Photoz_NN_scatter.png')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "jB8PgXsG_Q08"
   },
   "source": [
    "ypred = model.predict(Xst_test)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "KMxHlNxDTD-h"
   },
   "source": [
    "### Revisión de aprendizaje\n",
    "    \n",
    "Calcule la fracción atípica y la desviación absoluta de la mediana normalizada para este conjunto de predicciones.\n",
    "\n",
    "<br>\n",
    "\n",
    "<details>\n",
    "<summary style=\"display: line-item;\">Haga clic aquí para la respuesta!</summary>\n",
    "<p>\n",
    "    \n",
    "```python\n",
    "print(len(np.where(np.abs(y_test-ypred)>0.15*(1+y_test))[0])/len(y_test))\n",
    "\n",
    "print(1.48*np.median(np.abs(y_test-ypred)/(1 + y_test)))\n",
    "```\n",
    "\n",
    "</p>\n",
    "</details>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "K7rslnmK_Q08"
   },
   "source": [
    "Para mejorar aún más, podemos jugar con/optimizar los parámetros; una cosa que es muy interesante en mi opinión es ver el efecto de usar diferentes pérdidas en los residuos e intentar agregar más capas."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "6fV8VkFC_Q08"
   },
   "source": [
    "### Probemos algo de optimización con keras tuner"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "id": "veJnCwk8_Q08"
   },
   "source": [
    "# !pip3 install keras-tuner --upgrade    #si hace falta"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "wvw7d9oK_Q09"
   },
   "source": [
    "from keras_tuner.tuners import RandomSearch\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Parte del material a continuación está adaptado de la documentación de Keras Tuner\n",
    "\n",
    "# https://keras-team.github.io/keras-tuner/"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "JXOaqAvM_Q09"
   },
   "source": [
    "Esta función especifica cuáles parámetros queremos ajustar. Los parámetros ajustables pueden ser del tipo \"Choice\" (especificamos un conjunto), Int, Boolean o Float."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "2XgKwB1J_Q09"
   },
   "source": [
    "def build_model(hp):\n",
    "    model = keras.Sequential()\n",
    "    for i in range(hp.Int('num_layers', 2, 6)): #Probamos entre 2 y 6 capas\n",
    "        model.add(layers.Dense(units=hp.Int('units_' + str(i),\n",
    "                                            min_value=100, #Cada uno de ellos tiene 100-300 neuronas, en intervalos de 100\n",
    "                                            max_value=300,\n",
    "                                            step=100),\n",
    "                               activation='relu'))\n",
    "    model.add(Dense(1, activation='linear')) #el último\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(\n",
    "            hp.Choice('learning_rate', [1e-2, 1e-3, 1e-4])), #algunas tasas de aprendizaje\n",
    "        loss='mse')\n",
    "    return model"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "GmZr4Dgh_Q09"
   },
   "source": [
    "A continuación, especificamos cómo queremos explorar el espacio de parámetros. La búsqueda aleatoria es la opción más simple, pero a menudo bastante efectiva. Las alternativas son Hiperbanda (búsqueda aleatoria optimizada en la que se entrena una fracción mayor de modelos para un número menor de épocas, pero solo sobreviven las más prometedoras), o la optimización bayesiana, que intenta construir una interpretación probabilística de las notas del modelo (la probabilidad posterior de obtener una nota x, dados los valores de los hiperparámetros)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "XKTmAfeb_Q09"
   },
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_loss',\n",
    "    max_trials=40, #cantidad de combinaciones para probar\n",
    "    executions_per_trial=3,\n",
    "    project_name='My Drive/Photoz') #es posible que se debe eliminar o restablecer en el futuro"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "IfwvvlOE_Q09"
   },
   "source": [
    "Podemos visualizar el espacio de búsqueda así:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "GPJiiBOD_Q09"
   },
   "source": [
    "tuner.search_space_summary()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "kU7aZ8CL_Q0-"
   },
   "source": [
    "Finalmente, es hora de poner nuestro sintonizador a trabajar. (¡Este es un gran trabajo!)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "XrqAgLjg_Q0-"
   },
   "source": [
    "tuner.search(Xst_train, y_train, #igual a model.fit\n",
    "             epochs=100, validation_data=(Xst_val, y_val), batch_size=300, verbose = 0) \n",
    "\n",
    "#Nota: configurar la verbosidad en 0 no daría ningún resultado hasta que termine; tomó alrededor de ~ 35 minutos en mi computadora portátil"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "7FlfCn9m_Q0-"
   },
   "source": [
    "La función \"resultados\\_resumen(n)\" nos da acceso a los n mejores modelos. Es útil mirar algunos porque a menudo las diferencias son mínimas y ¡podríamos preferir un modelo más pequeño! Tenga en cuenta que el parámetro \"number of units\" (\"número de unidades) tendría un valor asignado para cada capa (incluso si el número de capas es menor en esa realización en particular)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "9AeqNold_Q0-"
   },
   "source": [
    "tuner.results_summary(5)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "kOE3vVSJ_Q0-"
   },
   "source": [
    "Las pérdidas de los primeros modelos son muy similares, lo que sugiere que 1. como de costumbre, necesitamos hacer algún tipo de validación cruzada para poder llegar a una clasificación, y 2. Con 3-5 capas y unos pocos cientos neuronas por capa, la configuración exacta no importa demasiado."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "dn06Jq-T_Q0-"
   },
   "source": [
    "best_hps=tuner.get_best_hyperparameters()[0] #elegir primer modelo"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "8qAU0mn1_Q0-"
   },
   "source": [
    "best_hps.get('learning_rate')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "5cLPW3MH_Q0-"
   },
   "source": [
    "best_hps.get('num_layers')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "9b_LsMsr_Q0-"
   },
   "source": [
    "#Tamaño de las capas\n",
    "\n",
    "print(best_hps.get('units_0'))\n",
    "print(best_hps.get('units_1'))\n",
    "print(best_hps.get('units_2'))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "bq8ULBCb_Q0_"
   },
   "source": [
    "model = tuner.hypermodel.build(best_hps) #obtener el mejor modelo"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "vilFKjD4_Q0_"
   },
   "source": [
    "model.build(input_shape=(None,6)) #construir el mejor modelo (si aún no se ajusta, esto le dará acceso al resumen)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "4nbegil5_Q0_"
   },
   "source": [
    "model.summary() #Mosca: esto es diferente a lo que vimos en el sumario del sintonizador"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "pUAM-_s4bOxL"
   },
   "source": [
    "Ahora, construya una red neuronal con los hiperparámetros óptimos."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "E_gLSfuK_Q0_"
   },
   "source": [
    "bestnet = model.fit(Xst_train, y_train, validation_data= (Xst_val, y_val), epochs=100, batch_size=300)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "rB6etYyXbXWI"
   },
   "source": [
    "También podemos mirar las curvas de entrenamiento vs validación para el modelo óptimo encontrado por el sintonizador."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ezQT_8iw_Q0_"
   },
   "source": [
    "plt.plot(bestnet.history['loss'], label = 'train')\n",
    "plt.plot(bestnet.history['val_loss'],'-.m', label = 'validation')\n",
    "plt.ylabel('Loss', fontsize = 14)\n",
    "plt.xlabel('Epoch', fontsize = 14)\n",
    "plt.ylim(0,0.1)\n",
    "plt.legend(loc='upper right', fontsize = 12)\n",
    "plt.legend(fontsize = 12);\n",
    "#plt.savefig('OptimalNN_Photoz.png',dpi=300)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "ic0vIKUObgJ7"
   },
   "source": [
    "Finalmente, informamos las notas de las pruebas para todas las métricas de interés (MSE, OLF, NMAD):"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "_C9_ECTO_Q0_",
    "scrolled": true
   },
   "source": [
    "model.evaluate(Xst_test, y_test)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "UbvdcdQs_Q1A"
   },
   "source": [
    "ypred = model.predict(Xst_test)\n",
    "\n",
    "#Calcular FOL\n",
    "\n",
    "print('OLF', len(np.where(np.abs(y_test-ypred)>0.15*(1+y_test))[0])/len(y_test))\n",
    "\n",
    "#Calcular la desviación absoluta de la mediana normalizada (NMAD)\n",
    "\n",
    "print('NMAD', 1.48*np.median(np.abs(y_test-ypred)/(1 + y_test)))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "JKO11my0_Q1A"
   },
   "source": [
    "Estos números se mejoraron, en comparación con la versión de referencia; si la mejora es significativa o no, debe determinarse mediante la validación cruzada."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "cAnGJLzv_Q1A"
   },
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "    \n",
    "plt.xlabel('True redshift', fontsize = 14)\n",
    "plt.ylabel('Estimated redshift', fontsize = 14)\n",
    "\n",
    "plt.scatter(y_test, model.predict(Xst_test), s =10, c = 'teal');\n",
    "\n",
    "plt.xlim(0,2)\n",
    "plt.ylim(0,2)\n",
    "plt.tight_layout()\n",
    "#plt.savefig('OptimalNN_scatter.png')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "GlJGKSCvbpq3"
   },
   "source": [
    "### A continuación, mostramos el efecto de cambiar la función de pérdida (MSE/MAE/MAPE), y estimamos las incertidumbres en las estimaciones de OLF/NMAD debido a la varianza de la muestra, para que podamos decidir si las diferencias son significativas."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "BBZ2v1aXbpq6"
   },
   "source": [
    "#### El modelo es el mejor modelo que encontré arriba (provino de una búsqueda aleatoria, es posible que encuentre uno diferente)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "mJytTFAS_Q1D"
   },
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "model = keras.Sequential()\n",
    "\n",
    "model.add(layers.Dense(units=300,\n",
    "                               activation='relu'))\n",
    "model.add(layers.Dense(units=200,\n",
    "                               activation='relu'))\n",
    "model.add(layers.Dense(units=100,\n",
    "                               activation='relu'))\n",
    "model.add(Dense(1, activation='linear')) #last one\n",
    "\n",
    "#Usamos tres funciones de pérdida diferentes y repetimos el entrenamiento 4x\n",
    "\n",
    "for loss in ['mse','mae', 'mape']:\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate = 0.01),\n",
    "        loss=loss)\n",
    "\n",
    "    OLF = np.zeros(4)\n",
    "    NMAD = np.zeros(4)\n",
    "\n",
    "    for i in range(0,4): #hagamos esto 4 veces y cambiemos solo la inicialización de pesos aleatorios\n",
    "    \n",
    "        model.fit(Xst_train, y_train,\n",
    "             epochs=100,\n",
    "             validation_data=(Xst_val, y_val), batch_size=300, verbose = 0)\n",
    "\n",
    "        ypred = model.predict(Xst_test)\n",
    "\n",
    "        #Calcular OLF\n",
    "\n",
    "        OLF[i] = len(np.where(np.abs(y_test-ypred)>0.15*(1+y_test))[0])/len(y_test)\n",
    "\n",
    "        #Calcular la desviación absoluta de la mediana normalizada (NMAD)\n",
    "        \n",
    "        NMAD[i] = 1.48*np.median(np.abs(y_test-ypred)/(1 + y_test))\n",
    "\n",
    "    print('OLF mean/std using loss', loss, 'is:', \"{:.3f}\".format(OLF.mean()), \"{:.3f}\".format(OLF.std()))\n",
    "    print('NMAD mean/std using loss', loss, 'is:', \"{:.2f}\".format(NMAD.mean()), \"{:.3f}\".format(NMAD.std()))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "yS05IVY-Z2L5"
   },
   "source": [
    "### Revisión de aprendizaje\n",
    "    \n",
    "¿Cuáles funciones de pérdida son las más adecuadas para minimizar el OLD y el NMAD?\n",
    "\n",
    "<br>\n",
    "\n",
    "<details>\n",
    "<summary style=\"display: list-item;\">Haga clic aquí para la respuesta!</summary>\n",
    "<p>\n",
    "    \n",
    "```\n",
    "Si queremos minimizar OLF/NMAD, nuestras opciones preferidas deberían ser las pérdidas MAE o MSE. En alternativa, podemos definir una pérdida personalizada.\n",
    "```\n",
    "\n",
    "</p>\n",
    "</details>"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
