{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V_z8Ds517LYD"
   },
   "source": [
    "Este es un \"notebook\" (cuaderno simple para explorar datos lineales con métodos de descenso de gradiente con algo de dispersión (no gaussiana).\n",
    "\n",
    "Acompaña al Capítulo 5 del libro (2 de 5).\n",
    "\n",
    "Autora: Viviana Acquaviva, con contribuciones de Jake Postiglione y Olga Privman."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "fOHrlUEZ7LYG",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1683408420760,
     "user_tz": 240,
     "elapsed": 214,
     "user": {
      "displayName": "Manuel Marcano",
      "userId": "17927109008814471837"
     }
    }
   },
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "%matplotlib inline\n",
    "\n",
    "font = {'size'   : 16}\n",
    "matplotlib.rc('font', **font)\n",
    "matplotlib.rc('xtick', labelsize=14) \n",
    "matplotlib.rc('ytick', labelsize=14) \n",
    "matplotlib.rcParams.update({'figure.autolayout': False})\n",
    "matplotlib.rcParams['figure.dpi'] = 300"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "V-W6jhRZ7LYI",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1683408442624,
     "user_tz": 240,
     "elapsed": 211,
     "user": {
      "displayName": "Manuel Marcano",
      "userId": "17927109008814471837"
     }
    }
   },
   "source": [
    "from sklearn import linear_model"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "w9WecX-67LYJ",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1683408463763,
     "user_tz": 240,
     "elapsed": 220,
     "user": {
      "displayName": "Manuel Marcano",
      "userId": "17927109008814471837"
     }
    }
   },
   "source": [
    "model = linear_model.LinearRegression()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "zzLFaCnJ7LYK",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1683408493756,
     "user_tz": 240,
     "elapsed": 471,
     "user": {
      "displayName": "Manuel Marcano",
      "userId": "17927109008814471837"
     }
    }
   },
   "source": [
    "np.random.seed(16) #establecer semilla con fines de reproducibilidad\n",
    "\n",
    "x = np.arange(100) \n",
    "\n",
    "yp = 3*x + 3 + 2*(np.random.poisson(3*x+3,100)-(3*x+3)) #generar algunos datos con dispersión siguiendo la distribución de Poisson\n",
    "                                                       #con valor exp = y del modelo lineal, centrado alrededor de 0"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bEHfwi027LYL"
   },
   "source": [
    "### Podemos usar nuestro conjunto de datos con valores atípicos del cuaderno anterior.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "LuTcDZiw7LYN",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1683408543225,
     "user_tz": 240,
     "elapsed": 303,
     "user": {
      "displayName": "Manuel Marcano",
      "userId": "17927109008814471837"
     }
    }
   },
   "source": [
    "np.random.seed(12) #establecer\n",
    "out = np.random.choice(100,15) #seleccionar 15 índices de valores atípicos\n",
    "yp_wo = np.copy(yp)\n",
    "np.random.seed(12) #establecer de nuevo\n",
    "yp_wo[out] = yp_wo[out] + 5*np.random.rand(15)*yp[out]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "reAeigQl7LYP",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1683408544625,
     "user_tz": 240,
     "elapsed": 614,
     "user": {
      "displayName": "Manuel Marcano",
      "userId": "17927109008814471837"
     }
    },
    "outputId": "4146eb08-0662-4581-f2f0-9cda279fe325"
   },
   "source": [
    "plt.scatter(x,yp_wo)\n",
    "plt.scatter(x,yp)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ej_uiSqW7LYR"
   },
   "source": [
    "Podemos ver el efecto en el error cuadrático medio\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tdjRFn8o7LYT",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1683408621547,
     "user_tz": 240,
     "elapsed": 192,
     "user": {
      "displayName": "Manuel Marcano",
      "userId": "17927109008814471837"
     }
    },
    "outputId": "f27fdb3b-2184-43ca-8b96-48343c0f73d2"
   },
   "source": [
    "model.fit(x.reshape(-1,1),yp_wo)\n",
    "\n",
    "pendiente, intercepto  = model.coef_, model.intercept_\n",
    "\n",
    "print(pendiente, intercepto)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B7yHAY8i7LYU"
   },
   "source": [
    "### Registro de aprendizaje\n",
    "    \n",
    "¿Cuál es la principal diferencia en la pendiente y el intercepto que encontraste, en comparación con el caso de que no haya valores atípicos?\n",
    "\n",
    "<details>\n",
    "<summary style=\"display: list-item;\">¡Haz clic aquí para la respuesta!</summary>\n",
    "<p>\n",
    "    \n",
    "```\n",
    "La pendiente cambia notablemente, de ~3 a ~4, porque los valores atípicos afectan en gran medida el error cuadrático medio. El intercepto también cambia significativamente (pero recuerda que el intercepto es mucho más difícil de identificar en un problema lineal).\n",
    "```\n",
    "    \n",
    "</p>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c7gWHpNG7LYW"
   },
   "source": [
    "### Ahora implementemos la forma más simple de descenso de gradiente: lote, estocástico y mini lote, uno por uno.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "61kpF7ga7LYW",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1683408871326,
     "user_tz": 240,
     "elapsed": 195,
     "user": {
      "displayName": "Manuel Marcano",
      "userId": "17927109008814471837"
     }
    },
    "outputId": "c83395b1-10c7-45f9-b487-8782bbd0f647"
   },
   "source": [
    "X = np.c_[np.ones((100, 1)), x] # agregue x0 = 1 a cada instancia; este es el término de sesgo\n",
    "\n",
    "print(X.shape) #la forma (shape en inglés) es número de instancias x número de parámetros"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ugsJw0eo7LYX",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1683408873818,
     "user_tz": 240,
     "elapsed": 215,
     "user": {
      "displayName": "Manuel Marcano",
      "userId": "17927109008814471837"
     }
    }
   },
   "source": [
    "theta_ne = np.array([[1.548],[3.978]])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "rgzu5R5h7LYX",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1683408874511,
     "user_tz": 240,
     "elapsed": 4,
     "user": {
      "displayName": "Manuel Marcano",
      "userId": "17927109008814471837"
     }
    }
   },
   "source": [
    "loss_ne = np.mean((X.dot(theta_ne) - yp_wo.reshape(-1,1))**2)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q1XYGmv57LYY",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1683408875736,
     "user_tz": 240,
     "elapsed": 5,
     "user": {
      "displayName": "Manuel Marcano",
      "userId": "17927109008814471837"
     }
    },
    "outputId": "2917abd2-67bb-4262-9b16-5fda93129ba8"
   },
   "source": [
    "loss_ne"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a7IfEbzE7LYZ"
   },
   "source": [
    "### Descenso de gradiente por lote. En inglés Batch Gradient Descent (GD)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "RVriRqPc7LYZ",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1683409028024,
     "user_tz": 240,
     "elapsed": 192,
     "user": {
      "displayName": "Manuel Marcano",
      "userId": "17927109008814471837"
     }
    }
   },
   "source": [
    "np.random.seed(10) #Mismas condiciones iniciales para todos.\n",
    "\n",
    "eta = 0.0001\n",
    "n_iterations = 1000 #¡Intenta cambiar el  número de iteraciones !\n",
    "m = 100\n",
    "\n",
    "theta_path_bgd = []\n",
    "\n",
    "theta = np.random.randn(2,1)\n",
    "\n",
    "for iteration in range(n_iterations):\n",
    "    gradients = 2/m * X.T.dot(X.dot(theta) - yp_wo.reshape(-1,1))\n",
    "    theta = theta - eta * gradients\n",
    "    theta_path_bgd.append(theta)\n",
    "\n",
    "theta_path_bgd = np.array(theta_path_bgd) #guardar el camino\n",
    "\n",
    "theta_bgd = theta #resultado final"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Lf8zJOIy7LYa",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1683409028798,
     "user_tz": 240,
     "elapsed": 4,
     "user": {
      "displayName": "Manuel Marcano",
      "userId": "17927109008814471837"
     }
    },
    "outputId": "7a147e6f-965b-4800-e470-7f862d42bc23"
   },
   "source": [
    "theta_bgd"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "sofilpcx7LYa",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1683409031207,
     "user_tz": 240,
     "elapsed": 228,
     "user": {
      "displayName": "Manuel Marcano",
      "userId": "17927109008814471837"
     }
    }
   },
   "source": [
    "loss_bgd = np.sum(1/m*(X.dot(theta_bgd) - yp_wo.reshape(-1,1))**2)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jFVs6hHV7LYa",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1683409031402,
     "user_tz": 240,
     "elapsed": 5,
     "user": {
      "displayName": "Manuel Marcano",
      "userId": "17927109008814471837"
     }
    },
    "outputId": "c1a1f848-3f1b-4887-ec58-0ea3a6879e34"
   },
   "source": [
    "loss_bgd"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ivsGkseg7LYa"
   },
   "source": [
    "### Registro de aprendizaje\n",
    "\n",
    "¿Cuál es la diferencia porcentual entre el valor final de la pérdida encontrada por el Descenso de gradiente por lote y por la ecuación normal?\n",
    "\n",
    "<details>\n",
    "<summary style=\"display: list-item;\">¡Haz clic aquí para la respuesta!</summary>\n",
    "<p>\n",
    "    \n",
    "```\n",
    "(loss_ne-loss_bgd)/loss_ne*100\n",
    "\n",
    "(debe ser del orden de 10^-5, mostrando que descenso de gradiente por lote y la ecuación normal son esencialmente equivalentes.)\n",
    "```\n",
    "    \n",
    "</p>\n",
    "</details>\n",
    "\n",
    "¿Qué sucede con esta comparación si aumenta el número de iteraciones en el descenso de gradiente por lote?\n",
    "\n",
    "<details>\n",
    "<summary style=\"display: list-item;\">¡Haz clic aquí para la respuesta!</summary>\n",
    "<p>\n",
    "    \n",
    "```\n",
    "Deberían acercarse.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sMM0ZWlA7LYb"
   },
   "source": [
    "### Descenso de Gradientes Estocástico. En inglés Stochastic gradient descent  (SGD)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "0RU2i0ba7LYb",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1683409362733,
     "user_tz": 240,
     "elapsed": 469,
     "user": {
      "displayName": "Manuel Marcano",
      "userId": "17927109008814471837"
     }
    }
   },
   "source": [
    "np.random.seed(10) #Mismas condiciones iniciales para todos.\n",
    "\n",
    "theta = np.random.randn(2,1) \n",
    "\n",
    "eta = 0.000005\n",
    "\n",
    "n_iterations = 10000 #mas iteraciones\n",
    "\n",
    "theta_path_sgd = []\n",
    "\n",
    "for epoch in range(n_iterations):\n",
    "    \n",
    "        random_index = np.random.randint(m) # elegir un ejemplo de los datos\n",
    "        \n",
    "        x_one = X[random_index:random_index+1]\n",
    "        \n",
    "        y_one = yp_wo[random_index:random_index+1]\n",
    "        \n",
    "        gradients = 2 * x_one.T.dot(x_one.dot(theta) - y_one)\n",
    "        theta = theta - eta * gradients\n",
    "        theta_path_sgd.append(theta)                 \n",
    "\n",
    "theta_path_sgd = np.array(theta_path_sgd)\n",
    "\n",
    "theta_sgd = theta"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-zTvsgzg7LYc",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1683409363183,
     "user_tz": 240,
     "elapsed": 211,
     "user": {
      "displayName": "Manuel Marcano",
      "userId": "17927109008814471837"
     }
    },
    "outputId": "cd3ecdb8-cf27-48d1-be0c-7aad5b33b173"
   },
   "source": [
    "theta_sgd"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pcfi2Nwg7LYc"
   },
   "source": [
    "Una vez más, encontramos una theta similar, pero no exactamente la misma."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Uiv2CKWC7LYd",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1683409386711,
     "user_tz": 240,
     "elapsed": 4,
     "user": {
      "displayName": "Manuel Marcano",
      "userId": "17927109008814471837"
     }
    }
   },
   "source": [
    "loss_sgd = np.sum(1/m*(X.dot(theta_sgd) - yp_wo.reshape(-1,1))**2)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "23JMFCCk7LYd",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1683409387339,
     "user_tz": 240,
     "elapsed": 5,
     "user": {
      "displayName": "Manuel Marcano",
      "userId": "17927109008814471837"
     }
    },
    "outputId": "f1b1a6e5-f5a6-46d2-c879-367b1cae180a"
   },
   "source": [
    "loss_sgd"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2C8-t0tr7LYd",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1683409398522,
     "user_tz": 240,
     "elapsed": 307,
     "user": {
      "displayName": "Manuel Marcano",
      "userId": "17927109008814471837"
     }
    },
    "outputId": "1ce3f991-934c-46ba-d641-cf787adf199f"
   },
   "source": [
    "(loss_ne-loss_sgd)/loss_sgd*100 #diferencia porcentual con la ecuación normal"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H1-8hCWz7LYd"
   },
   "source": [
    "### Registro de aprendizaje\n",
    "\n",
    "¿Debería preocuparnos que el valor final de la pérdida para el descenso de gradientes estocástico no sea tan cercano al encontrado por la ecuación Normal?\n",
    "    \n",
    "\n",
    "<details>\n",
    "<summary style=\"display: list-item;\">¡Haz clic aquí para la respuesta!</summary>\n",
    "<p>\n",
    "    \n",
    "```\n",
    "No, porque sabemos que las fluctuaciones estadísticas de los algoritmos de descenso de gradientes estocástico son grandes y no se garantiza que la pérdida disminuya en cada paso.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mTPeN2AY7LYe"
   },
   "source": [
    "### Descenso de gradiente de mini-lote  .En inglés Mini batch (MGD)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fVtcK-uc7LYe",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1683409804100,
     "user_tz": 240,
     "elapsed": 5,
     "user": {
      "displayName": "Manuel Marcano",
      "userId": "17927109008814471837"
     }
    },
    "outputId": "45bd3647-345f-47a6-c50a-d5f20161ad24"
   },
   "source": [
    "# Consulte también las notas de implementación aquí (notas en inglés): https://sebastianraschka.com/faq/docs/sgd-methods.html\n",
    "\n",
    "np.random.seed(10)\n",
    "\n",
    "theta = np.random.randn(2,1) \n",
    "\n",
    "eta = 0.000005\n",
    "\n",
    "n_iterations = 1000\n",
    "\n",
    "theta_path_mgd = []\n",
    "\n",
    "minibatch_size = 10 #tamaño del mini-lote\n",
    "\n",
    "for epoch in range(n_iterations):\n",
    "    \n",
    "    shuffled_indices = np.random.permutation(m) #Desordenar la matriz aleatoriamente.\n",
    "    \n",
    "    X_shuffled = X[shuffled_indices]\n",
    "    \n",
    "    y_shuffled = yp_wo.reshape(-1,1)[shuffled_indices]\n",
    "    \n",
    "    xi = X_shuffled[:minibatch_size]\n",
    "    \n",
    "    yi = y_shuffled[:minibatch_size]\n",
    "    \n",
    "    gradients = 2/minibatch_size * xi.T.dot(xi.dot(theta) - yi)\n",
    "    \n",
    "    theta = theta - eta * gradients\n",
    "    \n",
    "    theta_path_mgd.append(theta)\n",
    "\n",
    "theta_path_mgd = np.array(theta_path_mgd)\n",
    "\n",
    "theta_mgd = theta \n",
    "\n",
    "print(theta_mgd)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "jcY6jc2W7LYf",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1683409805209,
     "user_tz": 240,
     "elapsed": 221,
     "user": {
      "displayName": "Manuel Marcano",
      "userId": "17927109008814471837"
     }
    }
   },
   "source": [
    "loss_mgd = np.sum(1/m*(X.dot(theta_mgd) - yp_wo.reshape(-1,1))**2)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2Pzin12Z7LYf",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1683409793382,
     "user_tz": 240,
     "elapsed": 4,
     "user": {
      "displayName": "Manuel Marcano",
      "userId": "17927109008814471837"
     }
    },
    "outputId": "8e7ac17b-bab4-43d5-dc26-9539fdf0bace"
   },
   "source": [
    "loss_mgd"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cItHWsn47LYf",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1683409818513,
     "user_tz": 240,
     "elapsed": 6,
     "user": {
      "displayName": "Manuel Marcano",
      "userId": "17927109008814471837"
     }
    },
    "outputId": "f28a3144-f152-4620-bc93-24861fd6225f"
   },
   "source": [
    "(loss_ne-loss_mgd)/loss_ne*100 #diferencia porcentual con la ecuación normal"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m8AYwV5c7LYg"
   },
   "source": [
    "Lo mismo que antes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bHWCNW677LYg"
   },
   "source": [
    "Es muy interesante observar el camino tomado por el descenso de gradiente en los tres casos. Los colores cada vez más oscuros denotan pasos posteriores."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "DBOlPqpX7LYg",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1683409911455,
     "user_tz": 240,
     "elapsed": 2396,
     "user": {
      "displayName": "Manuel Marcano",
      "userId": "17927109008814471837"
     }
    },
    "outputId": "ee67a999-970c-4113-e3a1-f5278b09d800"
   },
   "source": [
    "plt.figure(figsize=(14,8))\n",
    "\n",
    "plt.scatter(theta_path_sgd[::10, 0].flatten(), theta_path_sgd[::10, 1].flatten(), marker = 's', s = 5, \\\n",
    "         label=\"DG Estocástico, N$_{it}$ = 10000\", c = np.arange(1000), cmap=plt.cm.Purples)\n",
    "plt.scatter(theta_path_mgd[:, 0].flatten(), theta_path_mgd[:, 1].flatten(), marker = \"+\", s = 12, linewidth=1, \\\n",
    "            label=\"DG Mini-lote, N$_{it}$ = 1000\", c = np.arange(1000), cmap=plt.cm.Greens)\n",
    "plt.scatter(theta_path_bgd[:, 0].flatten(), theta_path_bgd[:, 1].flatten(), marker = \"d\", s = 12, linewidth=1, \\\n",
    "            label=\"DG Lote, N$_{it}$ = 1000\", c = np.arange(1000,0,-1), cmap=plt.cm.copper)\n",
    "\n",
    "plt.scatter(theta_sgd[0],theta_sgd[1], marker = \"s\", s = 100, color = 'Purple', alpha = 0.5)\n",
    "plt.scatter(theta_mgd[0],theta_mgd[1], marker = \"+\", s = 200, color = 'DarkGreen', alpha = 1)\n",
    "plt.scatter(theta_bgd[0],theta_bgd[1], marker = \"d\", s = 100, color = 'k', alpha = 0.5)\n",
    "#plt.text(1.5,3.978,'Normal Equation solution X')\n",
    "\n",
    "legend = plt.legend(loc=\"upper left\", fontsize=16)\n",
    "\n",
    "\n",
    "for i in range(3):\n",
    "\n",
    "    legend.legendHandles[i].set_color('k')\n",
    "    legend.legendHandles[i]._sizes = [30]\n",
    "\n",
    "plt.xlabel(r\"$\\theta_0$\", fontsize=20)\n",
    "plt.ylabel(r\"$\\theta_1$   \", fontsize=20)\n",
    "\n",
    "plt.axis([1.3, 1.4, 2.5, 6.5])\n",
    "\n",
    "#plt.savefig('AllThePaths.png', dpi = 300)\n",
    "plt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gwfMbDVo7LYg"
   },
   "source": [
    "### Sin valores atípicos"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Bm8SIOZ07LYh",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1683410018915,
     "user_tz": 240,
     "elapsed": 285,
     "user": {
      "displayName": "Manuel Marcano",
      "userId": "17927109008814471837"
     }
    }
   },
   "source": [
    "#DG por Lotes\n",
    "\n",
    "np.random.seed(10) #Mismas condiciones iniciales para todos.\n",
    "\n",
    "eta = 0.0001\n",
    "n_iterations = 1000\n",
    "m = 100\n",
    "\n",
    "theta_path_bgd = []\n",
    "\n",
    "theta = np.random.randn(2,1)\n",
    "\n",
    "for iteration in range(n_iterations):\n",
    "    gradients = 2/m * X.T.dot(X.dot(theta) - yp.reshape(-1,1))\n",
    "    theta = theta - eta * gradients\n",
    "    theta_path_bgd.append(theta)\n",
    "\n",
    "theta_path_bgd = np.array(theta_path_bgd)\n",
    "\n",
    "#DG Estocástico:\n",
    "\n",
    "np.random.seed(10) #same initial conditions for all\n",
    "\n",
    "theta = np.random.randn(2,1) \n",
    "\n",
    "eta = 0.00005\n",
    "\n",
    "n_iterations = 1000\n",
    "\n",
    "theta_path_sgd = []\n",
    "\n",
    "for epoch in range(n_iterations):\n",
    "    \n",
    "        random_index = np.random.randint(m) # pick one example from the data \n",
    "        xi = X[random_index:random_index+1]\n",
    "        yi = yp[random_index:random_index+1]\n",
    "        gradients = 2 * xi.T.dot(xi.dot(theta) - yi)\n",
    "        theta = theta - eta * gradients\n",
    "        theta_path_sgd.append(theta)                 # not shown\n",
    "\n",
    "theta_path_sgd = np.array(theta_path_sgd)\n",
    "\n",
    "\n",
    "#DG por mini-lote:\n",
    "\n",
    "np.random.seed(10)\n",
    "\n",
    "theta = np.random.randn(2,1) \n",
    "\n",
    "eta = 0.0001\n",
    "\n",
    "n_iterations = 1000\n",
    "\n",
    "theta_path_mgd = []\n",
    "\n",
    "minibatch_size = 10\n",
    "\n",
    "for epoch in range(n_iterations):\n",
    "    \n",
    "    shuffled_indices = np.random.permutation(m) #Desordenar la matriz aleatoriamente.\n",
    "    X_shuffled = X[shuffled_indices]\n",
    "    y_shuffled = yp.reshape(-1,1)[shuffled_indices]\n",
    "    \n",
    "    xi = X_shuffled[0:minibatch_size] #sin reemplazo, técnicamente deberíamos\n",
    "    yi = y_shuffled[0:minibatch_size]\n",
    "    gradients = 2/minibatch_size * xi.T.dot(xi.dot(theta) - yi)\n",
    "    theta = theta - eta * gradients\n",
    "    theta_path_mgd.append(theta)\n",
    "\n",
    "theta_path_mgd = np.array(theta_path_mgd)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "gxSKdzWG7LYi",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1683410042989,
     "user_tz": 240,
     "elapsed": 2426,
     "user": {
      "displayName": "Manuel Marcano",
      "userId": "17927109008814471837"
     }
    },
    "outputId": "accf842d-3815-4474-affb-e363bbbcafa6"
   },
   "source": [
    "plt.figure(figsize=(14,8))\n",
    "plt.scatter(theta_path_bgd[:, 0].flatten(), theta_path_bgd[:, 1].flatten(), marker = \"d\", s = 12, linewidth=1, \\\n",
    "            label=\"Lote\", c = np.arange(1000,0,-1), cmap=plt.cm.copper)\n",
    "plt.scatter(theta_path_sgd[:, 0].flatten(), theta_path_sgd[:, 1].flatten(), marker = 's', s = 5, \\\n",
    "         label=\"Estocástico\", c = np.arange(1000), cmap=plt.cm.Purples)\n",
    "plt.scatter(theta_path_mgd[:, 0].flatten(), theta_path_mgd[:, 1].flatten(), marker = \"+\", s = 12, linewidth=1, \\\n",
    "            label=\"Mini-lote\", c = np.arange(1000), cmap=plt.cm.Greens)\n",
    "legend = plt.legend(loc=\"upper left\", fontsize=16)\n",
    "\n",
    "for i in range(3):\n",
    "\n",
    "    legend.legendHandles[i].set_color('k')\n",
    "    legend.legendHandles[i]._sizes = [30]\n",
    "\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lh8L-siR7LYi"
   },
   "source": [
    "Ejercicio 1: tenga en cuenta lo que sucede con tasas de aprendizaje más grandes y tasas de aprendizaje más pequeñas. ¿Sería una solución una tasa de aprendizaje adaptativa? Cualitativamente, ¿cómo lo elegirías?\n",
    "\n",
    "Ejercicio 2: Examine los gradientes para descubrir por qué el descenso de gradiente por lote deja de actualizar la pendiente con bastante rapidez. ¿Sería esto una preocupación en términos de quedarse atascado en mínimos locales (en funciones de pérdida que no son convexas)?\n"
   ]
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "BthV3VRc7SUi",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1683407848036,
     "user_tz": 240,
     "elapsed": 11,
     "user": {
      "displayName": "Manuel Marcano",
      "userId": "17927109008814471837"
     }
    }
   },
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "colab": {
   "provenance": []
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
