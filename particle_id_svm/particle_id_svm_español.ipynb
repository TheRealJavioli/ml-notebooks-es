{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Este es un cuaderno simple para construir y entrenar una Máquina de Vectores the Soporte (\"Support Vector Machine,\" SVM) para discriminar entre dos tipos de eventos de colisión.\n",
    "\n",
    "Acompaña al Capítulo 4 del libro.\n",
    "\n",
    "Los datos para este ejercicio fueron generosamente proporcionados por [Sascha Caron](https://www.nikhef.nl/~scaron/).\n",
    "\n",
    "Autora: Viviana Acquaviva, con contribuciones de Jake Postiglione y Olga Privman. Traducción a Español por Lucia Perez y Rosario Cecilio-Flores-Elie."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "source": [
    "### Primero se introduce los módulos de python pertinentes\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_predict, cross_validate\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import GridSearchCV"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "### Y se le dice a pandas como mostrar los datos\n",
    "\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "rc('text', usetex=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero se leen las características (\"featurues\") y las etiquetas (\"y\" aquí)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "features = pd.read_csv('../data/ParticleID_features.csv', index_col='ID')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "features.head(10)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "features.shape"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "y = np.genfromtxt('../data/ParticleID_labels.txt', dtype = str)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "y"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Las etiquetas que indican categorías (en cadena de caracteres, \"string-type\") se tienen que transformar a una matriz, e.g. 0 o 1."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder() #cambia lo categórico a 1...N "
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "y"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "y = le.fit_transform(y)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "y  # Mosca que esto es una 1 para la primera ocasión, pero de verdad queremos que \"4top\" sea la etiqueta positiva."
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "target = np.abs(y - 1)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "target # Mejor!"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Examinemos estas características, usando la propiedad \"describir\" (describe)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "features.describe() # Mosca: esto automáticamente excluye las columnas que no son de tipo numérico"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¡Importante!\n",
    "\n",
    "Si leemos la hilera de \"count\" (contar), se ve que el conjunto de data completo tiene 5,000 hileras, pero no todos las columnas existen para todos. Esto es porque una colisión crea un número de productos variable."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Opción 1: Solo usar las primeras 16 columnas (o, los primero cuatro productos) para tener menos problemas con calculaciones y manipulación de datos."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "features_lim = features[['MET', 'METphi', 'P1', 'P2', 'P3', 'P4', 'P5', 'P6', 'P7', 'P8', 'P9', 'P10', 'P11',\n",
    "       'P12',  'P13', 'P14', 'P15', 'P16']]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "features_lim.head(20)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "features_lim.describe() #esto automáticamente excluye las columnas que no son de tipo numérico, y no cuenta valores ausentes y \"NaNs\" (no un número)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¡Todavia hay columnas de característica de diferentes largos! Pueden existir valores NaN. Por ahora, se reemplazan con 0."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Examinemos la columna P10\n",
    "\n",
    "np.where(np.isnan(features_lim.P10))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Se mete un 0 donde este un NaN\n",
    "\n",
    "features_lim = features_lim.fillna(0) "
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ¿Que dará \"describe\" ahora?"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "features_lim.describe()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Muy bien - tenemos tamaños consistentes, y ahora podemos usarlos como matrices de caracteristica. PERO, seamos conscientes de los impactos negativos que pueden venir de estas estrategias de entrada."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Revisión de aprendizaje\n",
    "\n",
    "P: ¿Qué hace el método \"describe\" de pandas, y que nos cuenta de un marco de datos?\n",
    "    \n",
    "<details>\n",
    "    <summary style=\"display: list-item;\">¡Haga clic aquí para obtener la respuesta!</summary>\n",
    "    <p>\n",
    "         El método \"describe\" da la información y estadísticas útiles de los datos en el marco. Imprime el número total de objetos en el marco de datos, y otra información como: el promedio, la frecuencia, el mínimo, el máximo, y más. Mosca que solo mostrará esta información si aplica al tipo de dato en el marco: solo incluyera columnas numéricas.\n",
    "    </p>\n",
    "</details>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rápidamente, exploremos las etiquetas."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "np.sum(target)/len(target) #la distribución (ayuda a crear un punto de referencia)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "84% de etiquetas con negativos, 16% positivas. Esto en un poco desbalanceado; así, un clasificador que pone todo en la clase negativa tendrá una exactitud de 84%."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¿Porque no usamos un clasificador aleatorio, que asigna una clase aleatoria según la distribución de clases?"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Solución numérica\n",
    "\n",
    "acc=0\n",
    "for i in range(1000):\n",
    "    x = np.random.choice(target,5000)\n",
    "    acc += metrics.accuracy_score(target,x)\n",
    "print(acc/1000)\n",
    "\n",
    "\n",
    "# Solución analítica\n",
    "\n",
    "print(0.8378*(0.8378) + 0.1622*0.1622)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Empecemos con un modelo lineal: model = SVC()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Establecemos un punto de referencia: el modelo lineal, sin regularización (o, el C parámetro muy alto)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "bmodel = LinearSVC(dual = False, C = 1000) # se prefiere \"dual = False\" cuando el número de muestras es más grande que el número de características. ¡Si no, no se convergerá!"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=101) "
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "l_benchmark_lim = cross_validate(bmodel, features_lim, target, cv = cv, scoring = 'accuracy', return_train_score=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "l_benchmark_lim"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "np.round(l_benchmark_lim['test_score'].mean(),3), np.round(l_benchmark_lim['test_score'].std(), 3)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También es bueno revisar las etiquetas predichas. \"Cross\\_val\\_predict\" reunirá las etiquetas predichas cuando cada objeto estaba en el pliegue de prueba."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "ypred_bench_lim = cross_val_predict(bmodel, features_lim, target, cv = cv)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es un poco mejor que un clasificador aleatorio, pero peor que el clasificador bobo que le dice \"¡no!\" a todo."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¿Y si escalamos los valores?"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from sklearn.pipeline import make_pipeline # Con esto, se puede construir varias etapas a la vez"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "piped_model = make_pipeline(StandardScaler(), LinearSVC(dual = False, C = 1000)) #cambianos a SVC lineal\n",
    "\n",
    "benchmark_lim_piped = cross_validate(piped_model, features_lim, target, cv = cv, scoring = 'accuracy', return_train_score=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "benchmark_lim_piped"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "np.round(benchmark_lim_piped['test_score'].mean(),3), np.round(benchmark_lim_piped['test_score'].std(), 3)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se mejoró mucho, y aprendemos algo de lo que nos está dando problemas cuando comparamos las notas de entrenamiento y prueba. La manera formal de investigar esto es con las curvas de aprendizaje, que muestran la brecha entre las notas de entrenamiento y prueba, y también si se necesitan más datos."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Las curvas de aprendizaje"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from sklearn.model_selection import learning_curve"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def plot_learning_curve(estimator, title, X, y, ylim=None, cv=5,\n",
    "                        n_jobs=-1, train_sizes=np.linspace(.1, 1.0, 5), scoring = 'accuracy', scale = False):\n",
    "    \"\"\"\n",
    "    Generate a simple plot of the test and training learning curve.\n",
    "\n",
    "    Producir una gráfica simple de la curva de prueba y aprendizaje.\n",
    "\n",
    "    parámetros\n",
    "    ----------\n",
    "    estimator : (estimador) el tipo de objeto que implementa los métodos de \"fit\" (encajar) y \"predict\" (predecir).\n",
    "        Este tipo de objeto es el que se clona para cada validación. CONFIRM MEANING!!!\n",
    "    estimator : object type that implements the \"fit\" and \"predict\" methods\n",
    "        An object of that type which is cloned for each validation.\n",
    "\n",
    "    \n",
    "    title : cadena de caracteres\n",
    "        Título para la gráfica\n",
    "    \n",
    "    X : en forma de matriz, con forma de (n_samples, n_features)\n",
    "        El vector de entrenamiento, donde n_samples es el número de muestras, y n_features es el número de características\n",
    "\n",
    "    y : en forma de matriz, con forma de (n_samples) o (n_samples, n_features); opcional\n",
    "        Meta relacionada a X para clasificación o regresión; usar \"None\" (ninguno) para aprendizaje \n",
    "\n",
    "    ylim : tupla, con forma de  (ymin, ymax), opcional\n",
    "        Define los valores mímimos y máximos de valores-y trazados.\n",
    "\n",
    "    cv : entero, generador de entre-validación o un iterable, opcional\n",
    "        Determina la estrategia de entre-validación con divisiones.\n",
    "        Entradas posibles para cv incluyen:\n",
    "          - None (ninguno), para usar la entre-validación de 3 pliegues (por defecto),\n",
    "          - entero, para precisar cuantos pliegues,\n",
    "          - :term:`CV splitter (entre-validación separador)`,\n",
    "          - un iterable que rinde divisiones de (entrenamiento, prueba) como matrices de índices.\n",
    "\n",
    "        Para entradas de enteros o None, si ``y`` es binario o de varias clases, se utiliza :class:`StratifiedKFold`.\n",
    "        Si el estimador no es clasificador, o si ``y`` no es binario o de varias clases, se utiliza :class:`KFold`.\n",
    "\n",
    "        Consultar a :ref:`User Guide <cross_validation>` para aprender de los diferentes entre-validadores que se pueden usar aquí.\n",
    "\n",
    "    n_jobs : entero o None, optional (por defecto = None)\n",
    "        El número de trabajos que operarán en paralelo.\n",
    "         ``None`` significa 1 a menos si en el contexto de :obj:`joblib.parallel_backend`.\n",
    "        ``-1`` significa que usará todos los procesadores. Consultar a  :term:`Glossary <n_jobs>` para mas detalles.\n",
    "\n",
    "    train_sizes : en forma de matriz, con forma de (n_ticks,), dtype float or int\n",
    "        Los números de ejemplos de entrenamiento (relativo o absolutos) que se usarán en generar la curva de aprendizaje.\n",
    "        Si el dtype es float, train_sizes se usa como la fracción del tamaño máximo del conjunto de prueba (el cual se determina\n",
    "        con el método de validación actual); o, tiene que ser entre (0,1]. Si no, train_sizes se interpreta como los tamaños\n",
    "        absolutos de los conjuntos de entrenamiento. Mosca: para clasificación, el número de pruebas usualmente tiene que \n",
    "        ser suficiente para tener por lo menos una muestra de cada clase. (Por defecto: np.linspace(0.1, 1.0, 5))\n",
    "\n",
    "    \"\"\"\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "    plt.xlabel(\"núm. de ejemplos de entrenamiento\",fontsize = 14)\n",
    "\n",
    "    plt.ylabel(\"Nota de Exactitud\",fontsize = 14)\n",
    "\n",
    "    if (scale == True):\n",
    "        scaler = sklearn.preprocessing.StandardScaler()\n",
    "        X = scaler.fit_transform(X)\n",
    "\n",
    "    train_sizes, train_scores, test_scores = learning_curve(\n",
    "        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes, scoring = scoring)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "#    plt.grid()\n",
    "\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                     color=\"b\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"b\",\n",
    "             label=\"Nota de entrenamiento de entre-validación\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "             label=\"Nota de prueba de entre-validación\")\n",
    "\n",
    "    plt.legend(loc=\"best\",fontsize = 12)\n",
    "    return plt"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "#plot_learning_curve(piped_model, 'Generalized Learning Curves, linear SVC model, no reg', features_lim, target, train_sizes = np.array([0.05,0.1,0.2,0.5,1.0]), cv = KFold(n_splits=5, shuffle=True))\n",
    "plot_learning_curve(piped_model, 'Curvas de aprendizaje generalizado, modelo lineal de SVC, sin reg.', features_lim, target, train_sizes = np.array([0.05,0.1,0.2,0.5,1.0]), cv = KFold(n_splits=5, shuffle=True))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Revisión de aprendizaje\n",
    "\n",
    "P: Usando las curvas de aprendizaje, ¿que puede ser el problema, y como se puede mejorar el modelo?\n",
    "<details>\n",
    "    <summary style=\"display: list-item;\">¡Haga clic aquí para obtener la respuesta!</summary>\n",
    "    <p>\n",
    "        Este modelo padece de gran preferencia. Se nota en las curvas de aprendizaje, que muestran una brecha muy pequeña (y no importante estadísticamente) entre las notas de entrenamiento y prueba, para el tamaño actual de muestras (n = 4000). Esto por lo menos excluye a el problema de alta divergencia, y podemos enfocarnos en soluciones para gran preferencia. \n",
    "    </p>\n",
    "</details>\n",
    "\n",
    "<br/>\n",
    "\n",
    "P: ¿Nos ayudaría tener más datos? ¿Por qué sí o no?  \n",
    "\n",
    "<details>\n",
    "    <summary style=\"display: list-item;\">¡Haga clic aquí para obtener la respuesta!</summary>\n",
    "    <p>\n",
    "        No nos ayudaría. Más datos aumentaría la gráfica a la derecha, con más de 4000 muestras. Pero, las curvas de aprendizaje ya se estabilizaron\n",
    "        (ya se ven planas). Entonces, teniendo más datos no mejoraría las notas ni arreglaría el problema de gran preferencia.\n",
    "    </p>\n",
    "</details>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimización de Parámetros \n",
    "\n",
    "(mosca: esto NO es entre-validación anidada)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "piped_model = make_pipeline(StandardScaler(), SVC()) #no lineal para poder cambiar el kernel\n",
    "\n",
    "piped_model.get_params() # esto muestra como acceder parámetros para el escalador y el clasificador"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Se puede definir un cuadro de valores de parámetros para hacer la optimización. \n",
    "\n",
    "(Para estimar el error de generalización, se debe hacer una entre-validación anidada)\n",
    "\n",
    "Esto puede ser lento (tomo ~5 minutos en mi laptop, pero fue 15 en la previa); modelos más complejos (especialmente esos con alto gamma) toman más tiempo."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "source": [
    "#optimizing SVC: THIS IS NOT YET NESTED CV\n",
    "# optimizar SVC: ¡todavía no estamos en entre-validación anidada!\n",
    "\n",
    "parameters = {'svc__kernel':['poly', 'rbf'], \\\n",
    "              'svc__gamma':[0.00001,'scale', 0.01, 0.1], 'svc__C':[0.1, 1.0, 10.0, 100.0, 1000], \\\n",
    "              'svc__degree': [2, 4, 8]}\n",
    "\n",
    "model = GridSearchCV(piped_model, parameters, cv = StratifiedKFold(n_splits=5, shuffle=True), \\\n",
    "                     verbose = 2, n_jobs = 4, return_train_score=True)\n",
    "\n",
    "model.fit(features_lim,target)\n",
    "\n",
    "print('Mejors parámetros, y mejor nota:', \"{:.4f}\".format(model.best_score_), \\\n",
    "      model.best_params_)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualizar las notas en un marc de datos, y ordernar por nota de prueba.\n",
    "\n",
    "A mí me gusta ver el promedio, el std (desviación estándar), el preoedio de las notas de entrenamiento (por si acaso son muy diferentes, y para entender lo que significa el resultado), y también el tiempo total de ajuste (queremos escoger el modelo más rápido si todo lo otro es igual)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "source": [
    "scores_lim = pd.DataFrame(model.cv_results_)\n",
    "\n",
    "scores_lim[['params','mean_test_score','std_test_score','mean_train_score', \\\n",
    "            'mean_fit_time']].sort_values(by = 'mean_test_score', ascending = False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### También podemos aislar y estudiar un tipo de kernel a la vez."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "source": [
    "scores_lim[scores_lim['param_svc__kernel'] == 'poly'][['params','mean_test_score','std_test_score',\\\n",
    "                        'mean_train_score','mean_fit_time']].sort_values(by = 'mean_test_score', ascending = False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "source": [
    "scores_lim.columns"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diagnóstico final"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El problema aquí es la preferencia muy alta, que no me sorprende porque solo estamos usando parte de las características.\n",
    "\n",
    "Podemos intentar dos cosas: inventar nuevas características que mejorarán los valores (usando lo que sabemos del problema físico), y utilizar una estrategia de entrar datos que incluye información de características desechadas."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Próximo paso: definir nuevas características. "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "source": [
    "features = features.fillna(0) # para excluir NaN"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "source": [
    "features = features.replace('', 0) # para remplazar cadenas sin ningún caráceter con 0 "
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "scrolled": true
   },
   "source": [
    "features.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "source": [
    "np.unique(features.Type_1.values)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero se puede ver que tipos de partículas tenemos después de la colisión."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "source": [
    "np.unique(np.array([features['Type_'+str(i)].values for i in range(1,14)]).astype('str'))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estas son las nuevas características sugeridas (la justificación se puede ver en Capítulo 4 del libro)\n",
    "    \n",
    "    1. número total de partículas producidas\n",
    "    2. número total de b jets\n",
    "    3. número total de jets (chorros)\n",
    "    4. número total de leptons (électrons, positron, mu+, mu-)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "source": [
    "# contar el número de tipos no zero\n",
    "\n",
    "ntot = np.array([-(np.sum(np.array([features['Type_'+str(i)].values[j] == 0 for i in range(1,14)])) - 13) for j in range(features.shape[0])])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "source": [
    "# definir una columna nueva en el marco de datos\n",
    "\n",
    "features['Total_products'] = ntot"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "source": [
    "# contar el número de b jets\n",
    "\n",
    "nbtot = np.array([np.sum(np.array([features['Type_'+str(i)].values[j] == 'b' for i in range(1,14)])) for j in range(features.shape[0])])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "source": [
    "# definir una columna nueva en el marco de datos\n",
    "\n",
    "features['Total_b'] = nbtot"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "source": [
    "# Para esta, mejor contar todo los tipos (jets, photons g, e-, e+, mu-, mu+)\n",
    "\n",
    "njtot = np.array([np.sum(np.array([features['Type_'+str(i)].values[j] == 'j' for i in range(1,14)])) for j in range(features.shape[0])])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "source": [
    "ngtot = np.array([np.sum(np.array([features['Type_'+str(i)].values[j] == 'g' for i in range(1,14)])) for j in range(features.shape[0])])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "source": [
    "n_el_tot = np.array([np.sum(np.array([features['Type_'+str(i)].values[j] == 'e-' for i in range(1,14)])) for j in range(features.shape[0])])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "source": [
    "n_pos_tot = np.array([np.sum(np.array([features['Type_'+str(i)].values[j] == 'e+' for i in range(1,14)])) for j in range(features.shape[0])])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "source": [
    "n_muneg_tot = np.array([np.sum(np.array([features['Type_'+str(i)].values[j] == 'm-' for i in range(1,14)])) for j in range(features.shape[0])])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "source": [
    "n_mupos_tot = np.array([np.sum(np.array([features['Type_'+str(i)].values[j] == 'm+' for i in range(1,14)])) for j in range(features.shape[0])])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "source": [
    "n_lepton_tot = n_el_tot + n_pos_tot + n_muneg_tot + n_mupos_tot"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y así se definen las otras nuevas características:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "source": [
    "features['Total_j'] = njtot\n",
    "features['Total_g'] = ngtot\n",
    "features['Total_leptons'] = n_lepton_tot"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Revisión de aprendizaje\n",
    "\n",
    "¿Con cual método se puede ver las primeras filas de nuestro marco de características? <i>Prueba tu código en la próxima celda.</i>\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "source": [
    "# Escribe tu código aquí\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary style=\"display: list-item;\">¡Haga clic aquí para obtener la respuesta!</summary>\n",
    "<p>\n",
    "    \n",
    "```python\n",
    "features.head()\n",
    "```\n",
    "    \n",
    "</p>\n",
    "</details>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ingeniería de características 1: el impacto de impact variables ad-hoc"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "source": [
    "features_lim_2 = features[['MET', 'METphi', 'P1', 'P2', 'P3', 'P4', 'P5', 'P6', 'P7', 'P8', 'P9', 'P10', 'P11',\n",
    "       'P12',  'P13', 'P14', 'P15', 'P16','Total_products', 'Total_b' ,'Total_j','Total_g', \n",
    "              'Total_leptons']]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "source": [
    "bmodel # ¿te acuerdas de nuestro modelo de referencia?"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "source": [
    "piped_model = make_pipeline(StandardScaler(), LinearSVC(dual = False, C = 1000))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "source": [
    "benchmark_lim2_piped = cross_validate(piped_model, features_lim_2, target, cv = cv, scoring = 'accuracy', return_train_score=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "source": [
    "benchmark_lim2_piped"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "source": [
    "np.round(benchmark_lim2_piped['test_score'].mean(),3), np.round(benchmark_lim2_piped['test_score'].std(), 3)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "source": [
    "piped_model = make_pipeline(StandardScaler(), SVC())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este modelo se puede optimizar también; tomará tiempo, como antes."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "source": [
    "# optimizar SVC: toma tiempooooo\n",
    "\n",
    "parameters = {'svc__kernel':['poly', 'rbf'], \\\n",
    "              'svc__gamma':[0.00001,'scale', 0.01, 0.1], 'svc__C':[0.1, 1.0, 10.0, 100.0], 'svc__degree': [2, 4, 8]}\n",
    "\n",
    "nmodels = np.product([len(el) for el in parameters.values()])\n",
    "model = GridSearchCV(piped_model, parameters, cv = StratifiedKFold(n_splits=5, shuffle=True), \\\n",
    "                     verbose = 2, n_jobs = 4, return_train_score=True)\n",
    "model.fit(features_lim_2,target)\n",
    "\n",
    "print('Best params, best score:', \"{:.4f}\".format(model.best_score_), \\\n",
    "      model.best_params_)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "source": [
    "scores_lim_2 = pd.DataFrame(model.cv_results_)\n",
    "scores_lim_2[['params','mean_test_score','mean_train_score','mean_fit_time']].sort_values(by = 'mean_test_score', \\\n",
    "                                                    ascending = False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Otro tipo de ingeniería de característica que se puede intentar es usar el tipo de producto en el sitio <i>i</i> como una característica."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede hacer codificando la etiqueta, pero esto introduce la idea de una métrica de distancia (etiquetas mapeadas a 0 y 1 se interpretan a ser más cercanas a ellas mismas, que etiquetas mapeadas entre 0 y 7.)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos agregar nuevas columnas para cada etiqueta de categoría, y usar 0/1 para indicar que la partícula es de ese tipo."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "source": [
    "features_add = pd.get_dummies(data=features, columns=['Type_'+str(i) for i in range(1,14)])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "source": [
    "features_add.columns[58:80]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "source": [
    "features_add.shape"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ingeniería de características 1: agregar otros variables (tipo de producto)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "source": [
    "features_lim_3 = features_add[['MET', 'METphi', 'P1', 'P2', 'P3', 'P4', 'P5', 'P6', 'P7', 'P8', 'P9', 'P10', 'P11',\n",
    "       'P12',  'P13', 'P14', 'P15', 'P16','Total_products', 'Total_b' ,'Total_j','Total_g', \n",
    "              'Total_leptons','Type_1_b',\n",
    "       'Type_1_j', 'Type_2_0', 'Type_2_b', 'Type_2_e+', 'Type_2_e-',\n",
    "       'Type_2_g', 'Type_2_j', 'Type_2_m+', 'Type_2_m-', 'Type_3_0',\n",
    "       'Type_3_b', 'Type_3_e+', 'Type_3_e-', 'Type_3_g', 'Type_3_j',\n",
    "       'Type_3_m+', 'Type_3_m-', 'Type_4_0', 'Type_4_b', 'Type_4_e+',\n",
    "       'Type_4_e-', 'Type_4_g', 'Type_4_j', 'Type_4_m+', 'Type_4_m-']]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "source": [
    "features_lim_3.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "source": [
    "piped_model = make_pipeline(StandardScaler(), LinearSVC(dual = False, C = 10**3))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "source": [
    "benchmark = cross_validate(piped_model, features_lim_3, target, cv = cv, scoring = 'accuracy', return_train_score=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "source": [
    "benchmark"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "source": [
    "np.round(benchmark['test_score'].mean(),3), np.round(benchmark['test_score'].std(), 3)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "source": [
    "np.round(benchmark['train_score'].mean(),3), np.round(benchmark['train_score'].std(), 3)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### No se ve que se mejoró, pero debemos optimizar el modelo."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "source": [
    "piped_model = make_pipeline(StandardScaler(), SVC())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "source": [
    "# optimizar SVC: \n",
    "\n",
    "parameters = {'svc__kernel':['poly', 'rbf'], \\\n",
    "              'svc__gamma':[0.00001,'scale', 0.01, 0.1], 'svc__C':[0.1, 1.0, 10.0, 100.0, 1000.0], 'svc__degree': [4]} #poly never helps\n",
    "nmodels = np.product([len(el) for el in parameters.values()])\n",
    "model = GridSearchCV(piped_model, parameters, cv = StratifiedKFold(n_splits=5, shuffle=True), \\\n",
    "                     verbose = 2, n_jobs = 4, return_train_score=True)\n",
    "model.fit(features_lim_3,target)\n",
    "\n",
    "print('Best params, best score:', \"{:.4f}\".format(model.best_score_), \\\n",
    "      model.best_params_)\n",
    "\n",
    "scores_lim_3 = pd.DataFrame(model.cv_results_)\n",
    "scores_lim_3[['params','mean_test_score','mean_train_score','mean_fit_time']].sort_values(by = 'mean_test_score', \\\n",
    "                                                    ascending = False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Por fin, podemos intentarlo con todas las características."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "source": [
    "features_add.shape"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "source": [
    "piped_model = make_pipeline(StandardScaler(), LinearSVC(dual = False, C = 1000))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "source": [
    "cv"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "source": [
    "benchmark = cross_validate(piped_model, features_add, target, cv = cv, scoring = 'accuracy', return_train_score=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "source": [
    "benchmark"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "source": [
    "np.round(benchmark['test_score'].mean(),3), np.round(benchmark['test_score'].std(), 3)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "source": [
    "np.round(benchmark['train_score'].mean(),3), np.round(benchmark['train_score'].std(), 3)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Revisión de aprendizaje\n",
    "\n",
    "P: Con todos estos cambios y nuevos puntos de referencia, ¿que se nota de nuestro modelo? ¿Tiene todavía gran preferencia?\n",
    "<details>\n",
    "    <summary style=\"display: list-item;\">¡Haga clic aquí para obtener la respuesta!</summary>\n",
    "<p>\n",
    "    \n",
    "Se ve que el modelo no tiene más rasgos de gran preferencia, ¡pero ahora hay una alta divergencía! Esto no me sorprende, y lo esperaba porque nuestros datos tienen mucho ruido cuando se usan todas las características.\n",
    "\n",
    "Es posible rehacer la optimización, pero es probable que no ayudará, teniendo en cuenta todo lo que hemos hecho.\n",
    "    \n",
    "</p>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "source": [
    "piped_model = make_pipeline(StandardScaler(), SVC())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "source": [
    "# optimizar SVC: ¡todavía no estamos en entre-validación anidada!\n",
    "\n",
    "parameters = {'svc__kernel':['poly', 'rbf'], \\\n",
    "              'svc__gamma':[0.00001, 0.001, 0.01, 0.1], 'svc__C':[0.1, 1.0, 10.0, 1000.0], 'svc__degree': [4]} #poly never helps\n",
    "nmodels = np.product([len(el) for el in parameters.values()])\n",
    "model = GridSearchCV(piped_model, parameters, cv = StratifiedKFold(n_splits=5, shuffle=True), \\\n",
    "                     verbose = 2, n_jobs = 4, return_train_score=True)\n",
    "model.fit(features_add,target)\n",
    "\n",
    "print('Best params, best score:', \"{:.4f}\".format(model.best_score_), \\\n",
    "      model.best_params_)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "source": [
    "scores_all = pd.DataFrame(model.cv_results_)\n",
    "scores_all[['params','mean_test_score','mean_train_score','mean_fit_time']].sort_values(by = 'mean_test_score', \\\n",
    "                                                    ascending = False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### La moraleja del cuento: ingeniería de características funciona a lo mejor si se usa conocimiento del sujeto, y usando más características no siempe ayuda."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
