{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "En este cuaderno, calcularemos la importancia de característica para diferentes metodos de ensemblaje usando árboles, para predecir los corrimientos al rojo fotométricos para 6 bandas fotométricas (u, g, r, i, z, y). Acompaña a Capítulo 6 del libro.\n",
    "\n",
    "Autora: Viviana Acquaviva. Traducido por Lucia Perez y Rosario Cecilio-Flores-Elie. \n",
    "\n",
    "License: TBD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "\n",
    "\n",
    "font = {'size'   : 16}\n",
    "matplotlib.rc('font', **font)\n",
    "matplotlib.rc('xtick', labelsize=14) \n",
    "matplotlib.rc('ytick', labelsize=14) \n",
    "#matplotlib.rcParams.update({'figure.autolayout': True})\n",
    "matplotlib.rcParams['figure.dpi'] = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor \n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor, GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel_features = pd.read_csv('../data/sel_features.csv', sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel_target = pd.read_csv('../data/sel_target.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel_target.values.ravel() #changes shape to 1d row-like array"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Primeros serán los Bosques Aleatorios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestRegressor(max_features=4, n_estimators=200) #Mosca de re-asignar el estado aleatorio"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Después de encajar el modelo, tendrá el atributo de \"feature\\_importances\\_\" (importancias de característica). Así las podemos estudiar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.fit(sel_features, sel_target.values.ravel()) \n",
    "\n",
    "# nota: esto no parte los datos entre entrenamiento/prueba, está encajando con el conjunto entero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.feature_importances_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y este código marca las importancias de característica:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = model.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Emprimir los rangos de características:\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "for f in range(sel_features.shape[1]):\n",
    "    print(\"%d. feature: %s, %d (%f)\" % (f + 1, sel_features.columns[indices[f]], indices[f], importances[indices[f]]))\n",
    "\n",
    "# Marcar las importancias de características del bosque:\n",
    "plt.figure(figsize=(16,6))\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(sel_features.shape[1]), importances[indices],\n",
    "       color=\"r\", align=\"center\")\n",
    "plt.xticks(range(sel_features.shape[1]), sel_features.columns[indices])\n",
    "plt.xlim([-1, sel_features.shape[1]])\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### En este ejemplo, todas las características son importantes, pero es difícil diagnosticar problemas.\n",
    "\n",
    "### Lo que se puede hacer es comparar con los resultados de otros algoritmos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Marcar las importancias de características de los tres métodos:\n",
    "\n",
    "plt.figure(figsize=(16,6))\n",
    "\n",
    "plt.title(\"Feature importances for various models\")\n",
    "\n",
    "models = [RandomForestRegressor(max_features=4, n_estimators=200), \\\n",
    "          AdaBoostRegressor(base_estimator=DecisionTreeRegressor(max_depth=None), n_estimators=100), \n",
    "          xgb.XGBRegressor(objective ='reg:squarederror', max_depth=6, n_estimators = 500, learning_rate=0.1)]\n",
    "\n",
    "model_names = ['Random Forests', 'AdaBoost', 'XGBoost']\n",
    "\n",
    "for i, model in enumerate(models):\n",
    "\n",
    "    model.fit(sel_features, sel_target.values.ravel()) \n",
    "    \n",
    "    importances = model.feature_importances_\n",
    "    \n",
    "    indices = np.argsort(importances)[::-1]\n",
    "    \n",
    "    plt.bar(np.arange(sel_features.shape[1])+0.1*i, importances, \n",
    "            align=\"center\", width=0.7, alpha = 0.5, label = model_names[i])\n",
    "    \n",
    "    plt.xticks(range(sel_features.shape[1]), sel_features.columns)\n",
    "    \n",
    "    plt.xlim([-1, sel_features.shape[1]])\n",
    "    \n",
    "    plt.legend(fontsize = 12)   \n",
    "    \n",
    "#    print('For model', model_names[i], 'features importances are', sel_features.columns[indices].values, importances[indices])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tenemos que acordarnos que la importancia de característica es solo una señal, y casi siempre depende en cual algoritmo se usó. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sumario del problema de fuga en las etiquetas de prueba\n",
    "\n",
    "- Cuando optimizamos parámetros usando una búsqueda en cuadro, escogemos los parámetros que tienes las mejores notas de prueba. Esto es diferente a lo que pasaría con nuevos datos -- para ser justos, absolutamente no podemos mirar a las etiquetas de pruebas mientras estamos entrenando. Entonces, se tiene que usar la <b> validación cruzada anidada </b> para evaluar el error en generalizar, para no tener fuga entre el proceso de optimizar los parámeteros y el proceso de validación cruzada.\n",
    "<br>\n",
    "\n",
    "- Técnicamente, estandarizar o normalizar los datos usando el conjunto entere de aprendizaje crea fuga entre los conjuntos de entrenamiento y de prueba (el conjunto de entrenamiento 'sabe' del promedio y la desviación estándar de todos los datos). Esto usalmente no es tan dramático, pero lo correcto sería estandarizar o normalizar solo el conjunto de entrenamiento entre cada iteración de validación cruzada (ó: después de separar entre entrenamiento y prueba), y aplicar la misma transformación al conjunto de prueba. Así el modelo es un !!!canal!!!.\n",
    "<br>\n",
    "\n",
    "- Técnicamente, seleccionando características usando el conjunto entero de aprendizaje crea fuga entre los conjuntos de entrenamiento y de prueba (el modelo 'escoge' las características que dan los mejores resultados con el conjunto de prueba). Una forma de prevenir esto es escoger las características que son buenas pero no las mejores (las mediocres) entre un modelo con validación cruzada. !!!clarify meaning!!!A possible solution is to pick the \"average\" best features within a cross-validated model. \n",
    "</br>\n",
    "\n",
    "- Alternativamente , podemos usar procesos sin supervisión, por ejemplo escogiendo las características con la divergencia más alta. Esto lo podemos hacer con todos el conjunto de aprendizaje entero, porque no usa etiquetas--pero no elegirá las características pertinentes a un problema específico con supervisión. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
